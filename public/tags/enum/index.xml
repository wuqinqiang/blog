<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>enum on 记得</title>
    <link>https://www.syst.top/tags/enum/</link>
    <description>Recent content in enum on 记得</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 08 Dec 2021 22:25:52 +0800</lastBuildDate><atom:link href="https://www.syst.top/tags/enum/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>那些用Go实现的分布式事务框架</title>
      <link>https://www.syst.top/posts/go/transaction/</link>
      <pubDate>Wed, 08 Dec 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/transaction/</guid>
      <description>开篇 不知不觉竟然一个月没更新了，人一旦懒下来只会越来越懒。
最近对分布式事务产生了一些兴趣，查阅了一些文章以及论文。这篇文章主要介绍我看的两个项目，不涉及一些理论知识。
 阿里开源版本的Seata，主要看了Go实现的seata-golang(落后java版) 以及前段时间很多公众号都发的dtm。  Seata简介 Seata是由阿里开源的分布式事务服务，目前为用户提供了AT、TCC、SAGA、XA的事务模式，整体采用的是两阶段提交协议。Go版的seata-golang 目前好像只实现了mysql的AT、TCC模式，作者现在不咋更新了。
Seata 有几个核心角色：
 TC(Transaction Coordinator) -事务协调者。(维护全局和分支事务的状态，驱动全局事务提交或回滚) TM(Transaction Manager)-事务管理器。(定义全局事务的范围：开始全局事务、提交或回滚全局事务。) RM(Resource Manager)-资源管理器。(管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚)  当然这样看，可能还不是很理解，我拿一张官网的图加以解释。
从上图中可以看出，这三个角色所负责的工作如下，
TC
 维护全局和分支事务状态，需要进行存储。 当一个分布式事务处理结束，需要通知到每个RM是commit还是rollback。  TM
 向TC请求开启一个分布式事务，得到一个全局唯一的分布式id。 根据每个参与分布式事务的RM一阶段的反馈，决定二阶段向TC请求此次分布式事务是commit还是rollback(绝大部分场景下，一阶段任一RM失败，本次分布式事务失败)  RM
说的白一点就是管理参与分布式事务的各个服务(比如经典下单场景中涉及到的:订单服务、库存服务、营销服务等)
ps:个人感觉，这里的RM有点类似微服务中的中间处理层(专业术语他们管这叫bff-&amp;gt;backend for fronted)。
  一阶段 prepare 行为(主动)：每个RM调用 自定义 的 prepare 逻辑。
  二阶段 commit 行为(被动触发)：如果本次分布式事务第一阶段全部RM成功，TC处理完自身状态变更后，调用各个RM自定义 的 commit 逻辑。(一阶段RM全部成功)
  二阶段 rollback 行为(被动触发)：如果本次分布式事务第一阶段任一RM失败，TC处理完自身状态变更后，调用各个RM自定义 的 rollback 逻辑。(一阶段任意RM失败)
  好了。下面可以看看seata-golang 实现的一些细节了，seata-golang 底层采用gRPC进行通信。
seata-golang 我们先看RM部分结构。</description>
    </item>
    
    <item>
      <title>channel原理解析(二)</title>
      <link>https://www.syst.top/posts/go/channel2/</link>
      <pubDate>Sun, 10 Oct 2021 21:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/channel2/</guid>
      <description>上一篇文章主要介绍channel运行时是通过hchan表示的，也简单说明了hchan各个字段的含义。
我们提到，对channel的操作，本质上就是对hchan里字段的操作。因为在操作的过程中使用了互斥锁，所以保证了channel的并发安全。
这篇文章主要通过现实生活的一些例子来说明channel的一些原理，当然还是不会涉及过多源码。
无缓冲 我们都知道，channel分为无缓冲和缓冲。这两者最大的区别是什么？
我们用一个现实生活的快递例子来说明。
上面场景是快递员在等小库，当然反过来小库也可能在等快递员。
如果没有快递柜，快递员在送快递的过程中，如果家里没人，他就得在那等着，等着有人来签收快递，他才送货结束。
客户在快递员到来之前，他也不能离开家，不然快递来了没人收，所以他也得等到快递员上门，签字收了快递，他才算收货结束。
当然，客户不止有这家快递，如果快递员A在等的时候又来一个快递员B给他送货。这个快递员B不仅得等着，还得排队。等到客户到家后，肯定是先签收A的快递，然后再签收B的快递。
对应到无缓冲channel，
发送数据的时候，如果没有对应的接收者ready，那么发送者就进入到等待发送队列中，等待有对应的接收者唤醒它。
接收数据的时候，如果没有对应的发送者ready，那么接收者就进入到等待接收队列中，等待有对应的发送者唤醒它。
还记得上一篇文章我们介绍过hchan的结构吗。
其中recvq 表示等待接收消息的队列，sendq表示等待发送消息的队列。
我们来看waitq。
本质上waitq就是一个链表，更确切的说是一个双向循环的链表。其中waitq记录了链表的头尾，sudog记录了当前等待者的上一个等待者(prev)和下一个等待者(next)。
这就好像小库在签收完A的快递后喊，下一个是谁啊？
A会说:我的下一个是B。
B会说:是我。我记得我上一个是A，目前我没有下一个，所以我是最后一个。
缓冲 看完了无缓冲队列，我们再来看缓冲队列。还是用上面的故事，
只要快递柜有空闲柜子，快递员就可以直接把快递放到柜子里，让客户自己去柜子拿。如果发送没有空闲的柜子，那就只能等，等到别人告诉我有空闲柜子，我再把快递放到空出来的柜子里。
对应到缓冲channel，上面的快递柜，就是缓冲channel中存储数据的buffer。
对于发送者来说：只要缓冲区未满，发送者就可以继续发送数据存放在缓冲区。一旦缓冲区满了，发送者就只能进入到等待发送队列中，等待有对应的接收者唤醒它，然后它再把数据放入到刚刚被取走数据的位置。
对于接收者来说：只要缓冲区不为空，接收者就可以继续接收数据。一旦缓冲区空了，那么接收者就只能进入到等待接收队列中，等待有对应的发送者唤醒它。
上面还有什么问题吗？还真有。
我们取快递的时候，你一定会按照快递放入到快递柜的先后顺序取快递吗？咋么可能。
但是在channel中，是会保证消息的先进先出(FIFO)关系的。至于咋么保证的，我们终结篇解析代码细节的时候再说。
总结 这篇文章主要通过一个快递的例子来介绍channel操作的原理。下一篇我们介绍channel针对上述处理的细节逻辑。</description>
    </item>
    
    <item>
      <title>channel原理解析</title>
      <link>https://www.syst.top/posts/go/channel/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/channel/</guid>
      <description>躺的太久了，该起床了。宁可我卷死别人，不能让别人卷我。
之前断断续续看过Go几个模块的源码，可从未下笔，导致有些细节记不起来了。打算写一些文章重新记录。
channel源码解析的文章太多了。只用一篇文章的长篇大论大部分人没耐心看完，所以我打算分开写，最后附上完整的ppt。
当然这其中不会涉及过多细节源码，因为有时候，细节是魔鬼。
介绍 channel一些基础介绍这里就不过多涉及了，都1202年了，我不相信用过Go的人没用过channel。
当然下图也涵盖了大部分使用方法。注意是使用姿势，而不是模式。
顺便再提一句，有一道使用channel进行任务编排的经典的题。题目如下，
有四个goroutine，编号为 1、2、3、4。每秒钟会有一个 goroutine打印自己的编号。请你实现这个程序，让输出的编号总是按照 1、2、3、4、1、2、3、4、……的顺序打印出来。就像这样，
可以自己先思考下，代码也可以通过后台回复击鼓传花获取。
原理解析 从一个简单的例子说起。
创建一个main.go文件，代码如下，
我们来看看这段代码编译以后长啥样。
想得到go程序的汇编代码并不难。
可以使用go tool compile -N -l -S main.go生成汇编代码：
或者使用go tool compile -N -l main.go 先编译出代码，然后再使用go tool objdump main.o反汇编出代码。
当然，通过go build -gcflags -S main.go同样可以得到汇编的代码。
上面两种我就不演示了，可以自行实验。他们之中flag的具体含义也可以自行了解。
如果你觉得上面要自己敲代码比较麻烦，我推荐一个更加直接可视化的工具。
综上，从编译的代码我们可以看出，上述初始化一个channel,
ch := make(chan struct{}) 实际上调用的是runtime.makechan。我们来了解一下runtime.makechan。
从函数中，我们能知道最终返回一个runtime.hchan的指针。
runtime.hchan结构。
我们先来解释hchan结构体各个字段的含义，之后在案例介绍中会更加详细的说明他们的作用。
我们先来看qcount和dataqsiz有什么区别？
你去银行办事，银行有5个办事窗口，那么dataqsiz就等于5。在这里体现的是channel的容量为5。去银行的时候，当前有3个窗口有人正在办事，那么qcount就等于3，体现channel当前有3个数据元素。那么此时银行还可以再接待2个客户，对应还可以往channel发送2个数据元素。
其他字段现在看看说明就行了，后面会细讲。
到这里我们就知道创建一个channel本质上就是得到一个runtime.hchan的指针，后续对此chan的操作，无非就是对结构体字段进行相对应的操作。
同时我们也能猜出，为啥channel能在不同的g中传递消息，而对于使用者来说不用担心并发的问题，其实就是hchan内部使用互斥锁来保证了并发安全。
最后我们来看一下runtime.makechan函数核心实现，当然注释已经很明白了。
可以看到创建的时候有一段switch分支代码，那么什么情况下会走对应的case呢?
根据上面的信息，我们可以得出，
 如果创建一个无缓冲channel ，那么只需要为runtime.hchan本身分配一段内存空间即可。 如果创建的缓冲channel 存储的类型不是指针类型，会为当前 channel 和存储类型元素的缓冲区，分配一块连续的内存空间。 在默认情况下(缓冲channel存储类型包含指针)，会单独为runtime.hchan和缓冲区分配内存。  总结 这篇我们主要介绍了如何获取go程序的汇编代码，通过汇编代码知道创建channel的具体函数runtime.makechan，同时我们还知道不同的创建姿势会导致走向不同的内存空间分配。最后通过创建函数我们知道channel在程序运行时使用runtime.hchan来表示。</description>
    </item>
    
    <item>
      <title>iota 在 Go 中的使用 </title>
      <link>https://www.syst.top/posts/go/enum/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/enum/</guid>
      <description>介绍 Go 语言实际上没有直接支持枚举的关键字。一般我们都是通过 const + iota 实现枚举的能力。
有人要问了，为什么一定要使用枚举呢？stackoverflow 上有一个高赞的回答，如下:
You should always use enums when a variable (especially a method parameter) can only take one out of a small set of possible values. Examples would be things like type constants (contract status: &amp;quot;permanent&amp;quot;, &amp;quot;temp&amp;quot;, &amp;quot;apprentice&amp;quot;), or flags (&amp;quot;execute now&amp;quot;, &amp;quot;defer execution&amp;quot;). If you use enums instead of integers (or String codes), you increase compile-time checking and avoid errors from passing in invalid constants, and you document which values are legal to use.</description>
    </item>
    
    <item>
      <title>原来sync.Once还能这么用</title>
      <link>https://www.syst.top/posts/go/synconce/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/synconce/</guid>
      <description>介绍 sync.Once估计大家都不陌生，官方介绍中，
 Once is an object that will perform exactly one action
 正是因为这个特性，Once常常被用于单例对象的初始化场景。
也正是因为这个特性，其实它还能做一些其他的事情。
缓存击穿 日常背诵八股文，我相信你们对缓存击穿这个词特别熟悉。
缓存击穿一般待指热点key缓存失效(到期|删了)，同一时刻大量对热点key的并发请求。缓存找不到数据，所有请求都打入到DB层。此时，身为开发的你，明天和意外就不知道哪个先到了。
为了防止这种情况发生，针对相同key的请求，只需要一个请求(A)到达DB层取数据，其他请求等待A通知就行了。
就像这样，
​ 图片来源:caching
singleflight Go里有很多防缓存击穿的工具，比如singleflight库。
type call struct { wg sync.WaitGroup val interface{} err error forgotten bool //.....省略部分字段 } type Group struct { mu sync.Mutex m map[string]*call } 通过上面简单的代码大概能看出，其实就是对key做了缓存。
把一个key对应call结构存储在map中。保证只有一个key真正执行fn()服务 ，其他请求则通过sync.waitGroup的wait等待结果。
至于g.docall(c,key,fn)，
当带着全村人希望的那个请求，获取到数据，给对应key的call赋值，最终执行done，通知等待这个key全村的村民获取数据。
代码并不复杂。
自定义singleflight 我们也可以实现一个简易版本的。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) type CacheEntry struct { data []byte err error wait chan struct{} } type OrderSever struct { cache map[string]*CacheEntry mutex sync.</description>
    </item>
    
    <item>
      <title>推荐两款go开发中提高效率工具</title>
      <link>https://www.syst.top/posts/go/go-tool/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/go-tool/</guid>
      <description>介绍 推荐两款 go 开发中用的还行的工具。
为什么推荐工具？是为了让评论区的大佬介绍其他更好用的工具，解放我的双手。
顺便问问，有没有只说话就能自动打完代码的工具？
JSON-To-Stuct 这个工具可以把 json 格式的数据转换成 go 的 struct。比如你在对接第三方的时候，就不需要根据对方的接口一个个定义 struct 字段。下面示例复制的微信小商店商品 json 数据到网站的左框即可，当然自己还是需要做一些局部的调整。
其实这个功能 21 版的 goland 也支持了。在 goland 中你只需要这样,
Table-To-Stuct 被业务缠身的同学每天免不了 CURD。CURD 之前总得建表吧。建表之后总得在代码中定义模型吧。总不能又一个个字段定义，那么下面这个工具可能管用。
假设你有一个库 dream，库里有一个表 category，结构如下，
CREATE TABLE `category` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(20) NOT NULL DEFAULT &amp;#39;&amp;#39;, `parent_id` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;, `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`) ) ENGINE=InnoDB AUTO_INCREMENT=23 DEFAULT CHARSET=utf8mb4; 你只需引入包 github.</description>
    </item>
    
    <item>
      <title>无限缓冲的channel(1)</title>
      <link>https://www.syst.top/posts/go/unlimited/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/unlimited/</guid>
      <description>介绍 事情的起因是前几周看到鸟窝写了一篇关于实现无限缓冲 channel 的文章，当时忙着和小姐姐聊天没看，今天想起来了。
不过这篇文章不会涉及到鸟窝自己实现的 chanx，我们会在下一篇提到。
我们都知道，channel 有两种类型:无缓冲和有缓冲的。
当我们创建一个有缓冲的通道并指定了容量，那么在这个通道的生命周期内，我们将再也无法改变它的容量。
有时候，我们并不知道也无法预估写入通道的数量规模。如果此时通道的写入速度远远超过读取速度，那么必然会在某个时间点塞满通道，导致写入阻塞。 比如之前我翻译的一篇文章 使用 Go 每分钟处理百万请求 中，作者就出现处理速度太慢，导致通道塞满，其他请求被阻塞，响应时间慢慢增加。
此时有人就会提到，能不能提供一个无限缓冲(Unbounded or Unlimited)的通道。
这个问题早在 2017 年就有人提过 issues，最终 go 官方没有实现这个提案。
不过，这个 issues 下面总共产生了 67 个 comments，评论很精彩。 比如有人提到:
cznic:Unlimited capacity channels ask for a machine with unlimited memory. rsc:The limited capacity of channels is an important source of backpressure in a set of communicating goroutines. It is typically a mistake to use an unbounded channel, because you lose that backpressure.</description>
    </item>
    
    <item>
      <title>无限缓冲的channel(2)</title>
      <link>https://www.syst.top/posts/go/unlimited-2/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/unlimited-2/</guid>
      <description>chanx 上篇文章我们提到，当我们创建一个有缓冲的通道并指定了容量，那么在这个通道的生命周期内，我们将再也无法改变它的容量。 由此引发了关于无限缓存的 channel 话题讨论。 我们分析了一个实现无限缓冲的代码。 最后，我们也提到了它还可以继续优化的点。
鸟窝的 chanx 正是基于此方案改造而成的，我们来看看他俩的不同之处。
上篇文章说过，所谓的无限缓冲，无非是借助一个中间层的数据结构，暂存临时数据。
在 chanx 中，结构是这样的:
type UnboundedChan struct { In chan&amp;lt;- T // channel for write 	Out &amp;lt;-chan T // channel for read 	buffer *RingBuffer // buffer } in 和 out 的职责在上篇文章已经说明，这里的 buffer 就是我们所谓的中间临时存储层。其中的 RingBuffer 结构我们后面再说。
func NewUnboundedChan(initCapacity int) UnboundedChan { return NewUnboundedChanSize(initCapacity, initCapacity, initCapacity) } func NewUnboundedChanSize(initInCapacity, initOutCapacity, initBufCapacity int) UnboundedChan { in := make(chan T, initInCapacity) out := make(chan T, initOutCapacity) ch := UnboundedChan{In: in, Out: out, buffer: NewRingBuffer(initBufCapacity)} go process(in, out, ch) return ch } 它提供了两个初始化 UnboundedChan 的方法，从代码中我们可以明显的看出,NewUnboundedChanSize 可以给每个属性自定义自己的容量大小。仅此而已。</description>
    </item>
    
  </channel>
</rss>
