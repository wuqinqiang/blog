<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>go on 是不是很酷</title>
    <link>https://www.syst.top/tags/go/</link>
    <description>Recent content in go on 是不是很酷</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sun, 06 Nov 2022 10:11:22 +0800</lastBuildDate><atom:link href="https://www.syst.top/tags/go/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>easycar更新日记</title>
      <link>https://www.syst.top/posts/go/easycar2/</link>
      <pubDate>Sun, 06 Nov 2022 10:11:22 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/easycar2/</guid>
      <description>开篇 又拖更了一个多月，在思考人生的意义。
上一次介绍了新开发的一个分布式的事务框架easycar，这篇就当是对easycar的更新日记了。
服务注册与发现
由于easycar底层基于gRPC, 通过自定义Resolver接口还是很容易实现的。
负载均衡
客户端负载均衡，目前支持
  round-robin
  random
  power of 2 random choice
  consistent hash
  ip-hash
  least-load
  架构图
上次提到，参与的一组分布式事务可能部分操作存在先后顺序的问题。
我举了个例子，我们需要保证必须先执行account扣减余额和stock扣减库存服务成功后，才能创建订单order的服务。同时account和stock服务并不需要保证他们的执行顺序。下图，
以这个例子，那么实际在easycar中整个流程，
成功
失败
在easycar中，client负责和easycar(TC)端交互。主要负责注册分支，触发执行分布式事务以及查看状态等。
它并不会和RM产生联系。也就是说它不会负责去请求RM的第一阶段，这是和其他平台不同的一点。
TC全程接管和更新RM状态。
分支状态
项目地址:
Easycar: https://github.com/wuqinqiang/easycar
Client-go: https://github.com/easycar/client-go
Examples： https://github.com/easycar/examples</description>
    </item>
    
    <item>
      <title>一个用go实现的分布式事务框架</title>
      <link>https://www.syst.top/posts/go/easycar/</link>
      <pubDate>Mon, 12 Sep 2022 18:11:22 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/easycar/</guid>
      <description>开篇 对分布式事务一直感兴趣，之前一直被其他事情(懒)耽搁了，最近终于动手了。
easycar是什么 easycar 是一个用go实现的支持两阶段提交协议的分布式事务框架。目前还只支持TCC,SAGA 模式，其他模式待开发。
在介绍easycar 之前，先简单介绍几个角色。
Transaction Coordinator(TC) 负责全局事务的管理，所有参与分布式事务的分支都会注册到coordinator，回给每个分布式事务分配一个唯一id，
当然还包括驱动全局 begin / commit /abort(我喜欢称rollback)。
Transaction Manager (TM) 有些时候也叫 Transaction Client，当然不同的实现也许都会换个名字，但是职责都大差不差。
一般通过TM对每个参与的RM发起一阶段的请求，如果一阶段的RM全部成功，那么TM会向TC发起commit请求，否则发起rollback。
Resource Manager(RM) 用户维度的角色，管理本地事务处理的资源。其实你可以这么理解，假设你的订单服务部分接口参与了分布式事务，无论是第一阶段TM调用接口，还是TC第二阶段调用接口，你的订单服务都会去负责本地的事务修改。
那么 easycar 上述角色有什么不同吗？
有的。既然TC负责的就是全局事务的管理，那么我把职责都给了它。即由TC像每个参与的RM发起一阶段的请求，然后再根据一阶段的结果，发起二阶段的请求。由TC接管整个分布式事务的生命周期。
是的，我弱化了上面TM的能力。在我眼里，TM本质上就是一个客户端。客户端只需要做一些数据封装，简便化操作即可。所以即使没有客户端，其他语言的用户也可以直接通过http请求easycar服务接口。
所以理论上，大部分模式下，不需要客户端也是可以直接使用easycar服务的。
支持协议和事务模式同时混用 参与分布式事务的服务往往由不同的多个部门维护，或者部分新老项目交错，可能无法保证服务的协议是一致的。
另外，不同的服务所采用的事务模式具体是由：业务场景以及构造的成本来决定的。所以参与分布式事务之间所使用的事务模式不一定是统一的。
在这些基础上，easycar支持协议混用(目前支持http和原生的grpc服务)，支持部分事务模式混用(目前支持TCC,Saga)。
支持并发执行 假如现在有 order，account以及stock三个服务。
由这三个服务组成一个分布式事务。 当用户下单时，需要经过这三个服务中内部一些接口(account 扣钱，stock减库存，order 创建订单)。
如果只是同步执行第一阶段，那么第一阶段总执行时间= (account+stock+order)。
很多场景下，分布式事务之间并不会存在执行依赖先后的关系。所以多个子事务一阶段可以同时并发执行。
流程就像这样：
上图我们需要保证创建订单前必须先执行account扣减余额和stock扣减库存服务，才能创建订单order的服务。同时account和stock服务并不需要保证他们的执行顺序。
那么我们一阶段总执行耗时可以粗略=max(account,stock)+order。
因此，easycar是支持分层并发执行的。 对参与的RM通过设置的权重做分层，同一层的RM可以并发调用，一层处理完毕再接下一层。在这个基础上，当某个RM发生调用错误时，那么后面一层也不会执行了，整个分布式事务需要回滚。
异常处理 分布式事务中会出现一些问题，比如
  空补偿： Cancel请求到来时，Try还没有执行，这时候这样的请求我们不能执行，理应直接返回。
  悬挂： Try执行时，Cancel已执行完成，不能执行，直接返回。
  幂等： 所有操作的接口都存在这个问题。
  这些问题需要用户自己去解决，框架不会自动帮你处理。
在我看来，这些问题本身就是服务的必要工作，而不是通过外部服务来帮你保证。
换句话说，前端说它参数做了校验，难道后端就不校验接口了吗？</description>
    </item>
    
    <item>
      <title>Gnet原理解析</title>
      <link>https://www.syst.top/posts/go/gnet/</link>
      <pubDate>Tue, 07 Jun 2022 16:23:51 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/gnet/</guid>
      <description>距离上次写文章过了一月有余，这段时间着实太躺了。以至于昨晚做了一个噩梦，醒来的时候狠狠的抽了自己两巴掌，不能这么躺了。
上面当然是个笑话。
开篇 上一篇我们分析了Go原生网络模型以及部分源码，绝大部分场景下(99%)，使用原生netpoll已经足够了。
但是在一些海量并发连接下，原生netpoll会为每一个连接都开启一个goroutine处理，也就是1千万的连接就会创建一千万个goroutine。这就给了这些特殊场景下的优化空间，这也是像gnet和cloudwego/netpoll诞生的原因之一吧。
本质上他们的底层核心都是一样的，都是基于epoll(linux)实现的。
只是对事件发生后，每个库的处理方式会有所不同。
本篇文章主要分析gnet的。至于使用姿势就不发了，gnet有对应的demo库，可以自行体验。
架构 直接引用gnet官网的一张图
gnet采用的是『主从多 Reactors』。也就是一个主线程负责监听端口连接，当一个客户端连接到来时，就把这个连接根据负载均衡算法分配给其中一个sub线程，由对应的sub线程去处理这个连接的读写事件以及管理它的死亡。
下面这张图就更清晰了。
核心结构 我们先解释gnet的一些核心结构。
engine就是程序最上层的结构了。
  ln对应的listener就是服务启动后对应监听端口的监听器。
  lb对应的loadBalancer就是负载均衡器。也就是当客户端连接服务时，负载均衡器会选择一个sub线程，把连接交给此线程处理。
  mainLoop 就是我们的主线程了，对应的结构eventloop。当然我们的sub线程结构也是eventloop。结构相同，不同的是职责。主线程负责的是监听端口发生的客户端连接事件，然后再由负载均衡器把连接分配给一个sub线程。而sub线程负责的是绑定分配给他的连接(不止一个)，且等待自己管理的所有连接后续读写事件，并进行处理。
  接着看eventloop。
 netpoll.Poller:每一个 eventloop都对应一个epoll或者kqueue。 buffer用来作为读消息的缓冲区。 connCoun记录当前eventloop存储的tcp连接数。 udpSockets和connetcions分别管理着这个eventloop下所有的udp socket和tcp连接，注意他们的结构map。这里的int类型存储的就是fd。  对应conn结构，
这里面有几个字段介绍下，
 buffer:存储当前conn对端(client)发送的最新数据，比如发送了三次，那个此时buffer存储的是第三次的数据,代码里有。 inboundBuffer:存储对端发送的且未被用户读取的剩余数据，还是个Ring Buffer。 outboundBuffer:存储还未发送给对端的数据。(比如服务端响应客户端的数据，由于conn fd是不阻塞的，调用write返回不可写的时候，就可以先把数据放到这里)  conn相当于每个连接都会有自己独立的缓存空间。这样做是为了减少集中式管理内存带来的锁问题。使用Ring buffer是为了增加空间的复用性。
整体结构就这些。
核心逻辑 当程序启动时，
会根据用户设置的options明确eventloop循环的数量，也就是有多少个sub线程。再进一步说，在linux环境就是会创建多少个epoll对象。
那么整个程序的epoll对象就是count(sub)+1(main Listener)。
上图就是我说的，会根据设置的数量创建对应的eventloop,把对应的eventloop 注册到负载均衡器中。
当新连接到来时，就可以根据一定的算法(gnet提供了轮询、最少连接以及hash)挑选其中一个eventloop把连接分配给它。
我们先来看主线程，(由于我使用的是mac,所以后面关于IO多路复用，实现部分就是kqueue代码了，当然原理是一样的)
Polling就是等待网络事件到来，传递了一个闭包参数，更确切的说是一个事件到来时的回调函数，从名字可以看出，就是处理新连接的。
至于Polling函数，
逻辑很简单，一个for循环等待事件到来，然后处理事件。
主线程的事件分两种，
一种是正常的fd发生网络连接事件，
一种是通过NOTE_TRIGGER立即激活的事件。
通过NOTE_TRIGGER触发告诉你队列里有task任务，去执行task任务。
如果是正常的网络事件到来，就处理闭包函数，主线程处理的就是上面的accept连接函数。
accept连接逻辑很简单，拿到连接的fd。设置fd非阻塞模式(想想连接是阻塞的会咋么样?),然后根据负载均衡算法选择一个sub 线程，通过register函数把此连接分配给它。
register做了两件事，首先需要把当前连接注册到当前sub 线程的epoll or kqueue 对象中,新增read的flag。</description>
    </item>
    
    <item>
      <title>Go netpoll大解析</title>
      <link>https://www.syst.top/posts/go/netpoll/</link>
      <pubDate>Thu, 14 Apr 2022 10:23:51 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/netpoll/</guid>
      <description>开篇 之前简单看过一点go原生netpoll，没注意太多细节。最近从头到尾看了一遍，特写篇文章记录下。文章很长，请耐心看完，一定有所收获。
用户空间和内核空间 在linux中，经常能看到两个词语:User space(用户空间)和Kernel space (内核空间)。
简单的说， Kernel space是linux内核运行的空间，User space是用户程序运行的空间。它们之间是相互隔离的。
现代操作系统都是采用虚拟存储器。那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。空间分配如下图所示：
Kernel space可以调用系统的一切资源。User space 不能直接调用系统资源，在 Linux系统中，所有的系统资源管理都是在内核空间中完成的。比如读写磁盘文件、分配回收内存、从网络接口读写数据等等。应用程序无法直接进行这样的操作，但是用户程序可以通过内核提供的接口来完成这样的任务。比如像下面这样，
应用程序要读取磁盘上的一个文件，它可以向内核发起一个 “系统调用” 告诉内核：”我要读取磁盘上的某某文件”。其实就是通过一个特殊的指令让进程从用户态进入到内核态，在内核空间中，CPU 可以执行任何的指令，当然也包括从磁盘上读取数据。具体过程是先把数据读取到内核空间中，然后再把数据拷贝到用户空间并从内核态切换到用户态。此时应用程序已经从系统调用中返回并且拿到了想要的数据，继续往下执行用户空间执行逻辑。
这样的话，一旦涉及到对I/O的处理，就必然会涉及到在用户态和内核态之间来回切换。
io模型 网上有太多关于I/O模型的文章，看着看着有可能就跑偏了，所以我还是从 &amp;laquo;UNIX 网络编程&amp;raquo; 中总结的5中I/O模型说起吧。
Unix可用的5种I/O模型。
 阻塞I/O 非阻塞I/O I/O复用 信号驱动式I/O(SIGIO) 异步I/O(POSIX的aio_系列函数)  阻塞I/O 阻塞式I/O下，进程调用recvfrom，直到数据到达且被复制到应用程序的缓冲区中或者发生错误才返回，在整个过程进程都是被阻塞的。
非阻塞I/O 从图中可以看出，前三次调用recvfrom中没有数据可返回，因此内核转而立即返回一个EWOULDBLOCK错误。第四次调用recvfrom时已有一个数据报准备好，它被复制到应用程序缓冲区，于是recvfrom成功返回。
当一个应用程序像这样对一个非阻塞描述符循环调用recvfrom时，我们通常称为轮询(polling)，持续轮询内核，以这种方式查看某个操作是否就绪。
I/O多路复用 有了I/O多路复用(I/O multiplexing)，我们就可以调用 select 或者 poll，阻塞在这两个系统调用中的某一个之上，而不是阻塞在真正的I/O系统调用上。
上面这句话难理解是吧，说白了这里指的是，在第一步中，我们只是阻塞在select调用上，直到数据报套接字变为可读，返回可读条件，这里并没有发生I/O事件，所以说这一步，并没有阻塞在真正的I/O系统调用上。
其他两种就不过多介绍了。
还有一点，我们会经常提到同步I/O和异步I/O。
POSIX 把这两种术语定义如下:
 同步I/O操作(synchronous I/O opetation) 导致请求进程被阻塞，直到I/O操作完成。 异步I/O(asynchronous opetation) 不导致请求进程被阻塞。  基于上面的定义，
异步I/O的关键在于第二步的recrfrom是否会阻塞住用户进程，如果不阻塞，那它就是异步I/O。从上面汇总图中可以看出，只有异步I/O满足POSIX中对异步I/O的定义。
Go netpoller Go netpoller 底层就是对I/O多路复用的封装。不同平台对I/O多路复用有不同的实现方式。比如Linux的select、poll和epoll(具体差别不是很明白可以看这篇)。在MacOS则是kqueue,而Windows是基于异步I/O实现的icop&amp;hellip;&amp;hellip;，基于这些背景，Go针对不同的平台调用实现了多版本的netpoller。
下面我们通过一个demo开始讲解。
很简单一个demo，开启一个tcp服务。然后每来一个连接，就启动一个g去处理连接。处理完毕，关闭连接。
而且我们使用的是同步的模式去编写异步的逻辑，一个连接对应一个g处理，极其简单和易于理解。go标准库中的http.server也是这么干的。</description>
    </item>
    
    <item>
      <title>一个用go实现的有限状态机 </title>
      <link>https://www.syst.top/posts/go/easyfsm/</link>
      <pubDate>Sun, 06 Mar 2022 17:37:22 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/easyfsm/</guid>
      <description>easyfsm 之前看过新亮老哥的go-fsm-order，感觉还不错。最近在迁移项目的时候，发现有多处业务存在一些状态的流转，所以就基于go-fsm-order做了重改，让它可以在不同的业务场景下使用。
为什么不使用looplab/fsm，star挺多的啊。
不是特别喜欢，每次实例化fsm都需要重新传递对应events(虽然我们可以统一封装)，我更期望在项目启动时把此项目涉及到不同业务状态机流转注册到fsm，对应:不同业务-&amp;gt;[状态]-&amp;gt;[事件]-&amp;gt;处理事件主体(包含handler、params、hooks、observers等)。
当你开始进行状态流转时，只需要
fsm:=NewFsm(&amp;#34;业务名称&amp;#34;,&amp;#34;当前状态&amp;#34;) currentState,err:=fsm.Call(&amp;#34;事件名称&amp;#34;,&amp;#34;对应事件所需参数可选项&amp;#34;) 为什么需要区分业务？
因为绝大多数业务的状态值都是从数据库中获取的，比如订单表的订单状态，商品表中的商品状态，有可能值是相同的。
同一个业务同一属性对应状态值表达单一，不同业务下属性状态可能会出现值相同，但所表达的含义是不同的。
整体设计:
简单解释一下：
 业务:比如有商品状态业务、订单状态业务&amp;hellip;.. 状态：订单待付款、待发货&amp;hellip;. 事件：对应状态仅可达事件集合。比如待付款状态的可达事件仅有:支付事件和取消事件(取决于自己的业务) 执行事件主体：执行自定义的事件函数,如果有需要，还可以自定义执行事件前后hook，事件订阅者(比如支付事件发生后，异步通知用户等)  使用姿势 go get -u github.com/wuqinqiang/easyfsm 首先自定义业务、状态、事件。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/wuqinqiang/easyfsm&amp;#34; ) var ( // 业务 	businessName easyfsm.BusinessName = &amp;#34;order&amp;#34; // 对应状态 	initState easyfsm.State = 1 // 初始化 	paidState easyfsm.State = 2 // 已付款 	canceled easyfsm.State = 3 // 已取消  //对应事件 	paymentOrderEvent easyfsm.EventName = &amp;#34;paymentOrderEvent&amp;#34; cancelOrderEvent easyfsm.</description>
    </item>
    
    <item>
      <title>你还不体验泛型吗</title>
      <link>https://www.syst.top/posts/go/generics/</link>
      <pubDate>Sun, 02 Jan 2022 18:32:00 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/generics/</guid>
      <description>介绍 之前有看过官方发布的一些泛型文章，但是自己没动手玩过。还有没有没玩过的，那么最后一班车了。
不管学什么入门先从官网拿例子。
这段代码很简单，定义两个函数，计算对应传入的map值的和。两个函数最大的不同在于函数参数类型有所不同，一个map的值类型为int64,一个为float64，对应返回参数也有所不同。
在没有泛型的情况下，每种类型都不得不重新定义一个函数。
有人可能会说，上面的代码你可以这样写在一个函数里，
你确认这真的好吗？
泛型函数 但是，有了泛型之后，那就简单多了。
上面这段代码中，
定义了一个新函数SumIntsOrFloats，该函数声明两个类型参数 [K comparable, V int64 | float64]。其中K指定了类型必须为可比较(即可以用作比较符 == 和 !=)。因为 go中规定map的key必须是可比较类型。
比如，我们不能这样声明一个map。
所以这里的K就不能使用any关键字。
另一个V参数指定了一个约束，该约束由int64和float64组成，使用 | 指定了联合类型。
所以这里m参数为map[K]V类型，K,V即为参数类型指定的类型。
那么，如果你传入的map值的类型为其他类型。比如下面这种就不行了。
类型约束 上面看到的是我们在方法上对参数做一些约束。当然我们也可以直接声明类型约束。
上面的代码声明了一个Number用做类型约束的接口类型。在接口里声明int64和float64联合类型。
在SumNumbers中如果约束类型为int64或者 float64，那么只需要使用Number类型约束即可，就不用每个不同函数写 int64 | float64，达到代码复用的效果。
但是如果我这样，
我们把map中的值类型调整为自定义的otherInt64类型，otherInt64的基础类型也是int64。但是，这段代码编译会报错。
原因是 int64 约束会将其限制为只能是该类型，也就是只能是 int64，不能是基于此类型定义的其他类型。
如果想使用otherInt64咋么办，很简单，只需要一个～符号，
使用带～xxtype会将其限制为基础类型为xxtype的所有类型。
应用 上面只是简单介绍了一下使用姿势，那么哪些场景下可以使用泛型呢？
比如日常开发中，像slice、map、channel的一些处理函数，可能逻辑相同但是类型不同导致copy多个不同函数，这时候可以用泛型解决。比如，
还有一些行为方面的。比如 go 中的排序，通过泛型，不需要每一个结构都实现(Len，Less，Swap)三个方法，而是抽象出依赖于三个方法的行为。那么想要实现排序只需要依赖定义的这个抽象就行了。
其他方面的应用可以自行体验。
总结 这篇文章主要带你们体验下泛型的基本使用，以及对应的类型约束，最后还简单实验了两个泛型的场景demo，感兴趣的可以自行体验。更多内容，欢迎留言区域交流。
附录  https://go.dev/doc/tutorial/generics https://teivah.medium.com/when-to-use-generics-in-go-36d49c1aeda https://github.com/mattn/go-generics-example  </description>
    </item>
    
    <item>
      <title>那些用Go实现的分布式事务框架</title>
      <link>https://www.syst.top/posts/go/transaction/</link>
      <pubDate>Wed, 08 Dec 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/transaction/</guid>
      <description>开篇 不知不觉竟然一个月没更新了，人一旦懒下来只会越来越懒。
最近对分布式事务产生了一些兴趣，查阅了一些文章以及论文。这篇文章主要介绍我看的两个项目，不涉及一些理论知识。
 阿里开源版本的Seata，主要看了Go实现的seata-golang(落后java版) 以及前段时间很多公众号都发的dtm。  Seata简介 Seata是由阿里开源的分布式事务服务，目前为用户提供了AT、TCC、SAGA、XA的事务模式，整体采用的是两阶段提交协议。Go版的seata-golang 目前好像只实现了mysql的AT、TCC模式，作者现在不咋更新了。
Seata 有几个核心角色：
 TC(Transaction Coordinator) -事务协调者。(维护全局和分支事务的状态，驱动全局事务提交或回滚) TM(Transaction Manager)-事务管理器。(定义全局事务的范围：开始全局事务、提交或回滚全局事务。) RM(Resource Manager)-资源管理器。(管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚)  当然这样看，可能还不是很理解，我拿一张官网的图加以解释。
从上图中可以看出，这三个角色所负责的工作如下，
TC
 维护全局和分支事务状态，需要进行存储。 当一个分布式事务处理结束，需要通知到每个RM是commit还是rollback。  TM
 向TC请求开启一个分布式事务，得到一个全局唯一的分布式id。 根据每个参与分布式事务的RM一阶段的反馈，决定二阶段向TC请求此次分布式事务是commit还是rollback(绝大部分场景下，一阶段任一RM失败，本次分布式事务失败)  RM
说的白一点就是管理参与分布式事务的各个服务(比如经典下单场景中涉及到的:订单服务、库存服务、营销服务等)
ps:个人感觉，这里的RM有点类似微服务中的中间处理层(专业术语他们管这叫bff-&amp;gt;backend for fronted)。
  一阶段 prepare 行为(主动)：每个RM调用 自定义 的 prepare 逻辑。
  二阶段 commit 行为(被动触发)：如果本次分布式事务第一阶段全部RM成功，TC处理完自身状态变更后，调用各个RM自定义 的 commit 逻辑。(一阶段RM全部成功)
  二阶段 rollback 行为(被动触发)：如果本次分布式事务第一阶段任一RM失败，TC处理完自身状态变更后，调用各个RM自定义 的 rollback 逻辑。(一阶段任意RM失败)
  好了。下面可以看看seata-golang 实现的一些细节了，seata-golang 底层采用gRPC进行通信。
seata-golang 我们先看RM部分结构。</description>
    </item>
    
    <item>
      <title>那些用Go实现的分布式事务框架(2)</title>
      <link>https://www.syst.top/posts/go/transaction2/</link>
      <pubDate>Wed, 08 Dec 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/transaction2/</guid>
      <description>开篇 上一篇我们主要介绍的是seata-golang。一个对标seata的go语言实现，当然版本还是落后Java版很多的。
这次我们来介绍一下另一个go实现的分布式事务:dtm。
首先来看下dtm整体架构图(来源官网)。
再来看之前的seata架构图。
从架构上来看，大差不差。
seata中的TC对标dam的TM。
RM两边意思一致。
seata中的TM对标dtm事务SDK。作用都是一样:第一阶段开启一个全局事务,执行各RM分支事务，第二阶段根据RM第一阶段执行结果，决定调用TC(seata)|TM(dtm) commit或者rollback。
架构上，个人感觉只是因为模块名称以及图画不一样的差别。
当然在实现细节上还是有很大差别的。
我们先简单介绍下DTM各个模块。
TM TM 层在代码中是没有具体的主体结构的，开始都是函数之前的调用。
启动TM实际上开启了两个服务，http以及grpc这两个服务。
// StartSvr StartSvr func StartSvr() { app := common.GetGinApp() app = httpMetrics(app) addRoute(app) dtmimp.Logf(&amp;#34;dtmsvr listen at: %d&amp;#34;, common.DtmHttpPort) go app.Run(fmt.Sprintf(&amp;#34;:%d&amp;#34;, common.DtmHttpPort)) lis, err := net.Listen(&amp;#34;tcp&amp;#34;, fmt.Sprintf(&amp;#34;:%d&amp;#34;, common.DtmGrpcPort)) dtmimp.FatalIfError(err) s := grpc.NewServer( grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer( grpc.UnaryServerInterceptor(grpcMetrics), grpc.UnaryServerInterceptor(dtmgimp.GrpcServerLog)), )) dtmgimp.RegisterDtmServer(s, &amp;amp;dtmServer{}) dtmimp.Logf(&amp;#34;grpc listening at %v&amp;#34;, lis.Addr()) go func() { err := s.Serve(lis) dtmimp.FatalIfError(err) }() go updateBranchAsync() // 省略代码 } http路由，</description>
    </item>
    
    <item>
      <title>channel原理解析(三)</title>
      <link>https://www.syst.top/posts/go/channel3/</link>
      <pubDate>Sun, 10 Oct 2021 21:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/channel3/</guid>
      <description>上一篇文章主要通过一个现实例子间接反映channel的一些原理。最后一篇开始介绍一些细节，会涉及到源码。
还是从一个简单的代码程序看起。
我们创建了一个无缓冲channel，然后往这个channel发送数据。因为程序中没有读操作ready，所以发送的时候会阻塞。我们通过汇编代码看它底层的调用。
从图中我们看到，上述发送操作，程序运行时实际调用的runtime.chansend1。
最终chansend1最终调用的还是chansend，chansend的第三个参数block是个bool值，表示操作channel不能立即成功时是否需要阻塞。
具体哪些操作？
 向无缓冲channel发送数据且当前无接收者ready。 接收无缓冲channel数据且当前无发送者ready。 缓冲channel已满，往channel发送数据。 缓冲channel为空，接收channel数据 向一个nil的channel发送数据。(注意，向一个nil的channel发送数据并不会引发panic)。 向一个nil的channel接收数据。  碰到上面的操作，如果不是特殊处理，我们的应用程序会被阻塞，直到被唤醒。
当然对于向nil的channel发送|接收数据，后续再也没机会被唤醒了。
那么如果是快速试错的场景，是不是只要把block改成false，在失败的场景下就不会被阻塞了。
编译这段代码。
可以看出，上面这段代码编译后调用selectnbsend最终发送动作调用的还是chansned，只是传入的block是false。这样一旦操作失败，程序不会被阻塞。
同理我们可以得出接收的调用动作。
到这里我们已经知道，
发送数据，最终调用的runtime.chansend。
接收数据，最终调用的runtime.chanrecv。
接下来我们来说明这两个函数底层是如何操作的。
我们还是以一个无缓冲的channel和缓冲channel来说明。
来看一段简单的程序。
值得一提的是，在Go中使用 go func的时候，本质上调用的是runtime.newproc创建一个g，然后把这个g交给调度器调度。至于什么时候g被调度，然后执行你的代码逻辑，那就要看调度器的&amp;quot;心情&amp;quot;了。
所以上面创建的两个g(暂且称为g1和g2)，可以看成是我们向调度器提交了两个任务g，我们无法保证哪个g会被先调度器调度执行，因此我们也不确定发送和接收这两个操作，谁会先被执行。
假设g1先被调度器运行，然后执行代码ch&amp;lt;-struct{}{}。
如果g2先被调度器运行，然后执行代码&amp;lt;-ch。
当然我们也可以把上面的代码换成画成详细的无缓冲队列核心流程图。
缓冲channel发送的时候分为三种情况，想想我们上篇文章快递员送快递场景。
 如果快递柜未满，直接把快递放入到快递柜。(对应缓冲区未满，把发送数据拷贝到缓冲区) 如果快递柜满了，那快递员只能在那等待快递柜空了。(对应把当前g封装成sudog，然后把sudog放到等待发送消息队列sendq中，最后挂起当前g) 如果送快递的时候正好客户在那里等，那就直接把快递给他就是了(对应如果发送的时候发现有等待者，直接数据拷贝给他呗)  我们来创建一个例子。
我们创建了一个缓冲区为7的channel。buffer就是用来存储缓冲元素的，它实际上是一个环形数组。为什么是环形的？因为这样就可以达到复用空间的效果。
此时没有发送接收动作，所以qcount为0，发送(sendx)和接收(recvx)的位置都为0。
我们来看上面的第一种情况。缓冲区未满，
这块代码就比较简单了。如果缓冲区未满，那就把当前要发送的数据拷贝到缓冲区的发送位置，然后发送位置sendx+1，然后当然channel个数qcount+1，整个流程就结束了。
如果缓冲满的情况下，封装当前g成sudog，把这个sudog入队等待发送队列，最后调用gopark挂起当前g，上面无缓冲的时候有提到。
最后一种情况，发送的时候正好有等待接收消息者，那么就从recvq中拿出最早开始等待的接受者，然后把发送的数据直接拷贝给他。
send整体有两个动作：拷贝数据&amp;mdash;&amp;ndash;&amp;gt;唤醒等待的recvq。
那么对于接收操作呢？
 快递柜里有我的快递，那我直接拿就行了。(对应缓冲区有数据，根据读recvx的位置拿数据) 快递柜还没我的快递，但是快递哥打电话说快到了，那我现在楼下转转。(对应缓冲区无数据，把当前g封装成sudog,然后放入到等待接收消息队列recvq中)。 去拿一个快递的时候，正好一个快递员放我另一个快递的时候因为快递柜满了，在那等着。(对应缓冲区满了，且还有等待发送者。此时先到缓冲区获取当前读recvx位置的数据，然后再从等待发送者队列中取出最早等待的发送者，把他要发送的数据拷贝拷贝到当前我读取数据的位置(保证先入先出的顺序)，最后更新发送位置和更新位置即可)。  第一种情况就简单了。直接通过当前读位置recvx读取buffer对应的值，这里还需要通过判断是否忽略返回值，而决定需不需要往当前接收操作拷贝数据。然后移动recvx位置，元素个数qcount-- ，最后解锁即可。
第二种情况，封装当前g成sudog，把这个sudog入队等待接收队列，最后调用gopark挂起当前g。上面无缓冲的时候画过这个逻辑。
第三种情况有点复杂。
这种情况下，当获取到一个等待发送者，对于接收者来说，如果我们直接拿它的发送数据返回会发生什么？举个例子
上图，channel满了，且sendq有一个等待发送者(假设是G8，发送数据为800)，此时执行接收操作，也就出现上述第三种情况。
如果此时我们直接拿G8的数据，那么数据就不能保证先入先出了。
所以正确的操作是，读取当前recvx位置(0)buffer值100，然后把G8的数据800拷贝到0的位置，最后把recvq的位置向前移动，同步发送位置sendx等于recvq。这里，可以思考下为啥？
到这里缓冲channel的核心流程就说完了。如图，
另外后台回复channel有我准备的一个小ppt，可以跟着一起看。</description>
    </item>
    
    <item>
      <title>channel原理解析(二)</title>
      <link>https://www.syst.top/posts/go/channel2/</link>
      <pubDate>Sun, 10 Oct 2021 21:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/channel2/</guid>
      <description>上一篇文章主要介绍channel运行时是通过hchan表示的，也简单说明了hchan各个字段的含义。
我们提到，对channel的操作，本质上就是对hchan里字段的操作。因为在操作的过程中使用了互斥锁，所以保证了channel的并发安全。
这篇文章主要通过现实生活的一些例子来说明channel的一些原理，当然还是不会涉及过多源码。
无缓冲 我们都知道，channel分为无缓冲和缓冲。这两者最大的区别是什么？
我们用一个现实生活的快递例子来说明。
上面场景是快递员在等小库，当然反过来小库也可能在等快递员。
如果没有快递柜，快递员在送快递的过程中，如果家里没人，他就得在那等着，等着有人来签收快递，他才送货结束。
客户在快递员到来之前，他也不能离开家，不然快递来了没人收，所以他也得等到快递员上门，签字收了快递，他才算收货结束。
当然，客户不止有这家快递，如果快递员A在等的时候又来一个快递员B给他送货。这个快递员B不仅得等着，还得排队。等到客户到家后，肯定是先签收A的快递，然后再签收B的快递。
对应到无缓冲channel，
发送数据的时候，如果没有对应的接收者ready，那么发送者就进入到等待发送队列中，等待有对应的接收者唤醒它。
接收数据的时候，如果没有对应的发送者ready，那么接收者就进入到等待接收队列中，等待有对应的发送者唤醒它。
还记得上一篇文章我们介绍过hchan的结构吗。
其中recvq 表示等待接收消息的队列，sendq表示等待发送消息的队列。
我们来看waitq。
本质上waitq就是一个链表，更确切的说是一个双向循环的链表。其中waitq记录了链表的头尾，sudog记录了当前等待者的上一个等待者(prev)和下一个等待者(next)。
这就好像小库在签收完A的快递后喊，下一个是谁啊？
A会说:我的下一个是B。
B会说:是我。我记得我上一个是A，目前我没有下一个，所以我是最后一个。
缓冲 看完了无缓冲队列，我们再来看缓冲队列。还是用上面的故事，
只要快递柜有空闲柜子，快递员就可以直接把快递放到柜子里，让客户自己去柜子拿。如果发送没有空闲的柜子，那就只能等，等到别人告诉我有空闲柜子，我再把快递放到空出来的柜子里。
对应到缓冲channel，上面的快递柜，就是缓冲channel中存储数据的buffer。
对于发送者来说：只要缓冲区未满，发送者就可以继续发送数据存放在缓冲区。一旦缓冲区满了，发送者就只能进入到等待发送队列中，等待有对应的接收者唤醒它，然后它再把数据放入到刚刚被取走数据的位置。
对于接收者来说：只要缓冲区不为空，接收者就可以继续接收数据。一旦缓冲区空了，那么接收者就只能进入到等待接收队列中，等待有对应的发送者唤醒它。
上面还有什么问题吗？还真有。
我们取快递的时候，你一定会按照快递放入到快递柜的先后顺序取快递吗？咋么可能。
但是在channel中，是会保证消息的先进先出(FIFO)关系的。至于咋么保证的，我们终结篇解析代码细节的时候再说。
总结 这篇文章主要通过一个快递的例子来介绍channel操作的原理。下一篇我们介绍channel针对上述处理的细节逻辑。</description>
    </item>
    
  </channel>
</rss>
