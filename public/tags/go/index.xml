<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>go on 记得</title>
    <link>https://www.syst.top/tags/go/</link>
    <description>Recent content in go on 记得</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Tue, 27 Jul 2021 10:01:52 +0800</lastBuildDate><atom:link href="https://www.syst.top/tags/go/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超实用的 gRPC 客户端调试工具</title>
      <link>https://www.syst.top/posts/go/grpc/</link>
      <pubDate>Tue, 27 Jul 2021 10:01:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/grpc/</guid>
      <description>介绍 正好看到董泽润老哥写了一篇关于使用 WireShark 分析 gRPC 流量的文章，学到了。
那我就介绍两个日常开发使用过的两款 gRPC 客户端调试工具吧。
Evans Evans 有两种模式：REPL 和 CLI。比起其他 gRPC 客户端,更具有表现力。并且它还支持自动补全功能。
它的安装非常方便，在 Mac 上我们只需要执行以下两行命令即可。
$ brew tap ktr0731/evans $ brew install evans 我们来操作一下 REPL 模式。
首先我们需要有一个 pb 文件，假设你的文件在 api/api.proto，我们只需要这样： 默认地址为 127.0.0.1:50051，当然你可以通过 --host 和 --port 来指定服务器。 上图的命令:
 show package 读取 pb 包名， show service 显示对应服务列表。 call xxx 调用 grpc 服务&amp;hellip;&amp;hellip; &amp;hellip;..  更多命令可自行查阅官网。
除了上述这种直接引入 pb 文件外，我们还可以通过 gRPC 反射包(reflection)， 将 grpc.Server 注册到反射服务中, 这样的话，就可以通过 reflection 提供的反射服务查询到对应的 gRPC 服务或者调用 gRPC 服务。</description>
    </item>
    
    <item>
      <title>go并发-工作池模式</title>
      <link>https://www.syst.top/posts/go/worker-pool/</link>
      <pubDate>Thu, 01 Jul 2021 23:37:45 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/worker-pool/</guid>
      <description>开篇 之前写过一篇文章，它有个响亮的名字: Handling 1 Million Requests per Minute with Go。 这是国外的一个作者写的，我做了一篇说明。起的也是这个标题， 阅读量是我最好的一篇，果然文章都是靠标题出彩的&amp;hellip;..
今天偶然看到另一篇文章(原文在文末)。两篇文章原理相似:有一批工作任务(job)，通过工作池(worker-pool)的方式，达到多 worker 并发处理 job 的效果。
他们还是有很多不同的点，实现上差别也是蛮大的。
首先上一篇文章我放了一张图片，大概就是上篇整体的工作流。  每个 worker 处理完任务就好，不关心结果,不对结果做进一步处理。 只要请求不停止，程序就不会停止，没有控制机制，除非宕机。  这篇文章不同点在于:
首先数据会从 generate (生产数据)-&amp;gt;并发处理数据-&amp;gt;处理结果聚合。 图大概是这样的, 然后它可以通过 context.context 达到控制工作池停止工作的效果。
最后通过代码，你会发现它不是传统意义上的 worker-pool，后面会说明。
下图能清晰表达整体流程了。 顺便说一句，这篇文章实现的代码比 Handling 1 Million Requests per Minute with Go 的代码简单多了。
首先看 job。
package wpool import ( &amp;#34;context&amp;#34; ) type JobID string type jobType string type jobMetadata map[string]interface{} type ExecutionFn func(ctx context.Context, args interface{}) (interface{}, error) type JobDescriptor struct { ID JobID JType jobType Metadata map[string]interface{} } type Result struct { Value interface{} Err error Descriptor JobDescriptor } type Job struct { Descriptor JobDescriptor ExecFn ExecutionFn Args interface{} } // 处理 job 逻辑,处理结果包装成 Result 结果 func (j Job) execute(ctx context.</description>
    </item>
    
    <item>
      <title>如何优雅地实现并发编排任务</title>
      <link>https://www.syst.top/posts/go/test-tip/</link>
      <pubDate>Tue, 29 Jun 2021 07:44:45 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/test-tip/</guid>
      <description>开篇 在
场景1：调用第三方接口的时候， 一个需求你需要调用不同的接口，做数据组装。 场景2:一个应用首页可能依托于很多服务。那就涉及到在加载页面时需要同时请求多个服务的接口。这一步往往是由后端统一调用组装数据再返回给前端，也就是所谓的 BFF(Backend For Frontend) 层。
针对以上两种场景，假设在没有强依赖关系下，选择串行调用，那么总耗时即:
time=s1+s2+....sn 按照当代秒入百万的有为青年，这么长时间早就把你祖宗十八代问候了一遍。
为了伟大的KPI，我们往往会选择并发地调用这些依赖接口。那么总耗时就是:
time=max(s1,s2,s3.....,sn) 当然开始堆业务的时候可以先串行化，等到上面的人着急的时候，亮出绝招。
这样，年底 PPT 就可以加上浓重的一笔流水账:为业务某个接口提高百分之XXX性能，间接产生XXX价值。
当然这一切的前提是，做老板不懂技术，做技术”懂”你。
言归正传,如果修改成并发调用，你可能会这么写，
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) func main() { var wg sync.WaitGroup wg.Add(2) var userInfo *User var productList []Product go func() { defer wg.Done() userInfo, _ = getUser() }() go func() { defer wg.Done() productList, _ = getProductList() }() wg.Wait() fmt.Printf(&amp;#34;用户信息:%+v\n&amp;#34;, userInfo) fmt.Printf(&amp;#34;商品信息:%+v\n&amp;#34;, productList) } /********用户服务**********/ type User struct { Name string Age uint8 } func getUser() (*User, error) { time.</description>
    </item>
    
    <item>
      <title>leetcode 337 House Robber III</title>
      <link>https://www.syst.top/leetcode/337-house-robbe-riil/</link>
      <pubDate>Mon, 31 May 2021 00:36:26 +0800</pubDate>
      
      <guid>https://www.syst.top/leetcode/337-house-robbe-riil/</guid>
      <description>题目介绍 这是 House Robber III。
这道题和之前两个版本最大不同在于引入了二叉树。 树的每个节点(具体的房子)都有对应的值(金额)。每个节点有两种状态，偷或者不偷。 规则是不能同时偷父子节点， 比如上图，如果选择偷 A 节点，那么 B 和 C 就不能偷，既然 B 和 C 不能偷，那么 DEFG 就可以偷的。 因为 DEFG 和 A 是子孙关系，而不是父子关系。
这样的背景下，求小偷能偷的最大金额?
暴力递归 我们还是用上图的那个例子。我们可以直接求出最大金额,伪代码如下
/** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ // 求当前A节点能偷的最大金额res // 伪代码 item := node.Val + node.Left.Left.Val + node.Left.Right.Val + node.Right.Left.Val + node.Right.Right.Val res := max(item, node.</description>
    </item>
    
    <item>
      <title>leetcode 213 House Robber II</title>
      <link>https://www.syst.top/leetcode/213-house-robbe-rii/</link>
      <pubDate>Sun, 16 May 2021 00:17:52 +0800</pubDate>
      
      <guid>https://www.syst.top/leetcode/213-house-robbe-rii/</guid>
      <description>介绍 这是 House Robber II，也就是 I 的变型版本。II 和 I 的最大区别在于 II 把房子围城一个圈了. 你可以理解成环形链表。这样对小偷打击还是蛮大的，这意味着第一幢房子和最后一幢房子是紧挨着的。不能同时偷。 之前我们提到，相邻两家不能同时偷。如果只有一家，那么根本构不成相邻的条件，就偷唯一的那户人家。 如果有两家，那么偷的必然是两家中钱多的那家。
那如果总数大于 2 家呢？
对于第 n 家来说，只有两种选择:偷或者不偷。
是咋么计算出当前这家是否要偷的呢。
我们假设当前这家编号为 n,那么
max(我偷第 n 家的钱 + sum(截止第 n-2 家偷的钱), sum(截止第 n-1 家偷的钱，因为既然 n-1 家偷了，那么 n 必然是不能偷了))。
这才是这道题关于动态规划最核心的一个点。
看懂了吗？没看懂也没关系，手把手摸个图片出来。 还没看懂，加我微信 remember_wuqinqiang 我告诉你。这里顺便打个广告，没加我好友的赶紧加我好友。
最后，还需要考虑一个问题，如何确保偷了第一家就不偷最后一家，偷最后一家就不偷第一家。 很简单，直接定义两个dp，一个范围不包括第一家，一个范围不包括最后一家。 最后我们变成了求:
// 伪代码 最佳偷钱:=max(dp[不包括第一家],dp[不包括最后一家]) 那么剩下的就是对两个dp的状态转移公式了。
func rob(nums []int) int { n := len(nums) if n == 0 { return 0 } if n == 1 { return nums[0] } dp1, dp2 := make([]int, n), make([]int, n) dp1[0] = nums[0] dp1[1] = max(dp1[0], nums[1]) dp2[0] = 0 //dp2 不算第一家了 	dp2[1] = max(dp2[0], nums[1]) for i := 2; i &amp;lt; n; i++ { if i &amp;lt; n-1 { // dp1 不算最后一家 	dp1[i] = max(dp1[i-1], dp1[i-2]+nums[i]) } else { dp1[i] = dp1[i-1] } dp2[i] = max(dp2[i-1], dp2[i-2]+nums[i]) } return max(dp2[n-1], dp1[n-1]) } func max(x int, y int) int { if x &amp;gt; y { return x } return y } 其实代码还能更简洁。</description>
    </item>
    
    <item>
      <title>iota 在 Go 中的使用 </title>
      <link>https://www.syst.top/posts/go/enum/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/enum/</guid>
      <description>介绍 Go 语言实际上没有直接支持枚举的关键字。一般我们都是通过 const + iota 实现枚举的能力。
有人要问了，为什么一定要使用枚举呢？stackoverflow 上有一个高赞的回答，如下:
You should always use enums when a variable (especially a method parameter) can only take one out of a small set of possible values. Examples would be things like type constants (contract status: &amp;quot;permanent&amp;quot;, &amp;quot;temp&amp;quot;, &amp;quot;apprentice&amp;quot;), or flags (&amp;quot;execute now&amp;quot;, &amp;quot;defer execution&amp;quot;). If you use enums instead of integers (or String codes), you increase compile-time checking and avoid errors from passing in invalid constants, and you document which values are legal to use.</description>
    </item>
    
    <item>
      <title>推荐两款go开发中提高效率工具</title>
      <link>https://www.syst.top/posts/go/go-tool/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/go-tool/</guid>
      <description>介绍 推荐两款 go 开发中用的还行的工具。
为什么推荐工具？是为了让评论区的大佬介绍其他更好用的工具，解放我的双手。
顺便问问，有没有只说话就能自动打完代码的工具？
JSON-To-Stuct 这个工具可以把 json 格式的数据转换成 go 的 struct。比如你在对接第三方的时候，就不需要根据对方的接口一个个定义 struct 字段。下面示例复制的微信小商店商品 json 数据到网站的左框即可，当然自己还是需要做一些局部的调整。
其实这个功能 21 版的 goland 也支持了。在 goland 中你只需要这样,
Table-To-Stuct 被业务缠身的同学每天免不了 CURD。CURD 之前总得建表吧。建表之后总得在代码中定义模型吧。总不能又一个个字段定义，那么下面这个工具可能管用。
假设你有一个库 dream，库里有一个表 category，结构如下，
CREATE TABLE `category` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(20) NOT NULL DEFAULT &amp;#39;&amp;#39;, `parent_id` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;, `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`) ) ENGINE=InnoDB AUTO_INCREMENT=23 DEFAULT CHARSET=utf8mb4; 你只需引入包 github.</description>
    </item>
    
    <item>
      <title>无限缓冲的channel(1)</title>
      <link>https://www.syst.top/posts/go/unlimited/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/unlimited/</guid>
      <description>介绍 事情的起因是前几周看到鸟窝写了一篇关于实现无限缓冲 channel 的文章，当时忙着和小姐姐聊天没看，今天想起来了。
不过这篇文章不会涉及到鸟窝自己实现的 chanx，我们会在下一篇提到。
我们都知道，channel 有两种类型:无缓冲和有缓冲的。
当我们创建一个有缓冲的通道并指定了容量，那么在这个通道的生命周期内，我们将再也无法改变它的容量。
有时候，我们并不知道也无法预估写入通道的数量规模。如果此时通道的写入速度远远超过读取速度，那么必然会在某个时间点塞满通道，导致写入阻塞。 比如之前我翻译的一篇文章 使用 Go 每分钟处理百万请求 中，作者就出现处理速度太慢，导致通道塞满，其他请求被阻塞，响应时间慢慢增加。
此时有人就会提到，能不能提供一个无限缓冲(Unbounded or Unlimited)的通道。
这个问题早在 2017 年就有人提过 issues，最终 go 官方没有实现这个提案。
不过，这个 issues 下面总共产生了 67 个 comments，评论很精彩。 比如有人提到:
cznic:Unlimited capacity channels ask for a machine with unlimited memory. rsc:The limited capacity of channels is an important source of backpressure in a set of communicating goroutines. It is typically a mistake to use an unbounded channel, because you lose that backpressure.</description>
    </item>
    
    <item>
      <title>无限缓冲的channel(2)</title>
      <link>https://www.syst.top/posts/go/unlimited-2/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/unlimited-2/</guid>
      <description>chanx 上篇文章我们提到，当我们创建一个有缓冲的通道并指定了容量，那么在这个通道的生命周期内，我们将再也无法改变它的容量。 由此引发了关于无限缓存的 channel 话题讨论。 我们分析了一个实现无限缓冲的代码。 最后，我们也提到了它还可以继续优化的点。
鸟窝的 chanx 正是基于此方案改造而成的，我们来看看他俩的不同之处。
上篇文章说过，所谓的无限缓冲，无非是借助一个中间层的数据结构，暂存临时数据。
在 chanx 中，结构是这样的:
type UnboundedChan struct { In chan&amp;lt;- T // channel for write 	Out &amp;lt;-chan T // channel for read 	buffer *RingBuffer // buffer } in 和 out 的职责在上篇文章已经说明，这里的 buffer 就是我们所谓的中间临时存储层。其中的 RingBuffer 结构我们后面再说。
func NewUnboundedChan(initCapacity int) UnboundedChan { return NewUnboundedChanSize(initCapacity, initCapacity, initCapacity) } func NewUnboundedChanSize(initInCapacity, initOutCapacity, initBufCapacity int) UnboundedChan { in := make(chan T, initInCapacity) out := make(chan T, initOutCapacity) ch := UnboundedChan{In: in, Out: out, buffer: NewRingBuffer(initBufCapacity)} go process(in, out, ch) return ch } 它提供了两个初始化 UnboundedChan 的方法，从代码中我们可以明显的看出,NewUnboundedChanSize 可以给每个属性自定义自己的容量大小。仅此而已。</description>
    </item>
    
    <item>
      <title>为什么把 dig 迁移到 wire</title>
      <link>https://www.syst.top/posts/go/why-dig-to-wire/</link>
      <pubDate>Wed, 21 Apr 2021 23:54:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/why-dig-to-wire/</guid>
      <description>开篇 dig 和 wire 都是 Go 依赖注入的工具，那么，本质上功能相似的框架，为什么要从 dig 切换成 wire？
场景 我们从场景出发。
假设我们的项目分层是:router-&amp;gt;controller-&amp;gt;service-&amp;gt;dao。
大概就长这样:
现在我们需要对外暴露一个订单服务的接口。
首页看 main.go 文件。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/gin-gonic/gin&amp;#34; &amp;#34;github.com/wuqinqiang/digvswire/dig&amp;#34; &amp;#34;github.com/wuqinqiang/digvswire/router&amp;#34; ) func main() { serverStart() } func serverStart() { defer func() { if err := recover(); err != nil { fmt.Printf(&amp;#34;init app err:%v\n&amp;#34;, err) } }() e := gin.Default() di := dig.ContainerByDig() err := router.RegisterRouter(e, di) if err != nil { fmt.Printf(&amp;#34;register router err:%v&amp;#34;, err) } _ = e.</description>
    </item>
    
  </channel>
</rss>
