<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>go on 记得</title>
    <link>https://www.syst.top/tags/go/</link>
    <description>Recent content in go on 记得</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 08 Dec 2021 22:25:52 +0800</lastBuildDate><atom:link href="https://www.syst.top/tags/go/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>那些用Go实现的分布式事务框架</title>
      <link>https://www.syst.top/posts/go/transaction/</link>
      <pubDate>Wed, 08 Dec 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/transaction/</guid>
      <description>开篇 不知不觉竟然一个月没更新了，人一旦懒下来只会越来越懒。
最近对分布式事务产生了一些兴趣，查阅了一些文章以及论文。这篇文章主要介绍我看的两个项目，不涉及一些理论知识。
 阿里开源版本的Seata，主要看了Go实现的seata-golang(落后java版) 以及前段时间很多公众号都发的dtm。  Seata简介 Seata是由阿里开源的分布式事务服务，目前为用户提供了AT、TCC、SAGA、XA的事务模式，整体采用的是两阶段提交协议。Go版的seata-golang 目前好像只实现了mysql的AT、TCC模式，作者现在不咋更新了。
Seata 有几个核心角色：
 TC(Transaction Coordinator) -事务协调者。(维护全局和分支事务的状态，驱动全局事务提交或回滚) TM(Transaction Manager)-事务管理器。(定义全局事务的范围：开始全局事务、提交或回滚全局事务。) RM(Resource Manager)-资源管理器。(管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚)  当然这样看，可能还不是很理解，我拿一张官网的图加以解释。
从上图中可以看出，这三个角色所负责的工作如下，
TC
 维护全局和分支事务状态，需要进行存储。 当一个分布式事务处理结束，需要通知到每个RM是commit还是rollback。  TM
 向TC请求开启一个分布式事务，得到一个全局唯一的分布式id。 根据每个参与分布式事务的RM一阶段的反馈，决定二阶段向TC请求此次分布式事务是commit还是rollback(绝大部分场景下，一阶段任一RM失败，本次分布式事务失败)  RM
说的白一点就是管理参与分布式事务的各个服务(比如经典下单场景中涉及到的:订单服务、库存服务、营销服务等)
ps:个人感觉，这里的RM有点类似微服务中的中间处理层(专业术语他们管这叫bff-&amp;gt;backend for fronted)。
  一阶段 prepare 行为(主动)：每个RM调用 自定义 的 prepare 逻辑。
  二阶段 commit 行为(被动触发)：如果本次分布式事务第一阶段全部RM成功，TC处理完自身状态变更后，调用各个RM自定义 的 commit 逻辑。(一阶段RM全部成功)
  二阶段 rollback 行为(被动触发)：如果本次分布式事务第一阶段任一RM失败，TC处理完自身状态变更后，调用各个RM自定义 的 rollback 逻辑。(一阶段任意RM失败)
  好了。下面可以看看seata-golang 实现的一些细节了，seata-golang 底层采用gRPC进行通信。
seata-golang 我们先看RM部分结构。</description>
    </item>
    
    <item>
      <title>channel原理解析(三)</title>
      <link>https://www.syst.top/posts/go/channel3/</link>
      <pubDate>Sun, 10 Oct 2021 21:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/channel3/</guid>
      <description>上一篇文章主要通过一个现实例子间接反映channel的一些原理。最后一篇开始介绍一些细节，会涉及到源码。
还是从一个简单的代码程序看起。
我们创建了一个无缓冲channel，然后往这个channel发送数据。因为程序中没有读操作ready，所以发送的时候会阻塞。我们通过汇编代码看它底层的调用。
从图中我们看到，上述发送操作，程序运行时实际调用的runtime.chansend1。
最终chansend1最终调用的还是chansend，chansend的第三个参数block是个bool值，表示操作channel不能立即成功时是否需要阻塞。
具体哪些操作？
 向无缓冲channel发送数据且当前无接收者ready。 接收无缓冲channel数据且当前无发送者ready。 缓冲channel已满，往channel发送数据。 缓冲channel为空，接收channel数据 向一个nil的channel发送数据。(注意，向一个nil的channel发送数据并不会引发panic)。 向一个nil的channel接收数据。  碰到上面的操作，如果不是特殊处理，我们的应用程序会被阻塞，直到被唤醒。
当然对于向nil的channel发送|接收数据，后续再也没机会被唤醒了。
那么如果是快速试错的场景，是不是只要把block改成false，在失败的场景下就不会被阻塞了。
编译这段代码。
可以看出，上面这段代码编译后调用selectnbsend最终发送动作调用的还是chansned，只是传入的block是false。这样一旦操作失败，程序不会被阻塞。
同理我们可以得出接收的调用动作。
到这里我们已经知道，
发送数据，最终调用的runtime.chansend。
接收数据，最终调用的runtime.chanrecv。
接下来我们来说明这两个函数底层是如何操作的。
我们还是以一个无缓冲的channel和缓冲channel来说明。
来看一段简单的程序。
值得一提的是，在Go中使用 go func的时候，本质上调用的是runtime.newproc创建一个g，然后把这个g交给调度器调度。至于什么时候g被调度，然后执行你的代码逻辑，那就要看调度器的&amp;quot;心情&amp;quot;了。
所以上面创建的两个g(暂且称为g1和g2)，可以看成是我们向调度器提交了两个任务g，我们无法保证哪个g会被先调度器调度执行，因此我们也不确定发送和接收这两个操作，谁会先被执行。
假设g1先被调度器运行，然后执行代码ch&amp;lt;-struct{}{}。
如果g2先被调度器运行，然后执行代码&amp;lt;-ch。
当然我们也可以把上面的代码换成画成详细的无缓冲队列核心流程图。
缓冲channel发送的时候分为三种情况，想想我们上篇文章快递员送快递场景。
 如果快递柜未满，直接把快递放入到快递柜。(对应缓冲区未满，把发送数据拷贝到缓冲区) 如果快递柜满了，那快递员只能在那等待快递柜空了。(对应把当前g封装成sudog，然后把sudog放到等待发送消息队列sendq中，最后挂起当前g) 如果送快递的时候正好客户在那里等，那就直接把快递给他就是了(对应如果发送的时候发现有等待者，直接数据拷贝给他呗)  我们来创建一个例子。
我们创建了一个缓冲区为7的channel。buffer就是用来存储缓冲元素的，它实际上是一个环形数组。为什么是环形的？因为这样就可以达到复用空间的效果。
此时没有发送接收动作，所以qcount为0，发送(sendx)和接收(recvx)的位置都为0。
我们来看上面的第一种情况。缓冲区未满，
这块代码就比较简单了。如果缓冲区未满，那就把当前要发送的数据拷贝到缓冲区的发送位置，然后发送位置sendx+1，然后当然channel个数qcount+1，整个流程就结束了。
如果缓冲满的情况下，封装当前g成sudog，把这个sudog入队等待发送队列，最后调用gopark挂起当前g，上面无缓冲的时候有提到。
最后一种情况，发送的时候正好有等待接收消息者，那么就从recvq中拿出最早开始等待的接受者，然后把发送的数据直接拷贝给他。
send整体有两个动作：拷贝数据&amp;mdash;&amp;ndash;&amp;gt;唤醒等待的recvq。
那么对于接收操作呢？
 快递柜里有我的快递，那我直接拿就行了。(对应缓冲区有数据，根据读recvx的位置拿数据) 快递柜还没我的快递，但是快递哥打电话说快到了，那我现在楼下转转。(对应缓冲区无数据，把当前g封装成sudog,然后放入到等待接收消息队列recvq中)。 去拿一个快递的时候，正好一个快递员放我另一个快递的时候因为快递柜满了，在那等着。(对应缓冲区满了，且还有等待发送者。此时先到缓冲区获取当前读recvx位置的数据，然后再从等待发送者队列中取出最早等待的发送者，把他要发送的数据拷贝拷贝到当前我读取数据的位置(保证先入先出的顺序)，最后更新发送位置和更新位置即可)。  第一种情况就简单了。直接通过当前读位置recvx读取buffer对应的值，这里还需要通过判断是否忽略返回值，而决定需不需要往当前接收操作拷贝数据。然后移动recvx位置，元素个数qcount-- ，最后解锁即可。
第二种情况，封装当前g成sudog，把这个sudog入队等待接收队列，最后调用gopark挂起当前g。上面无缓冲的时候画过这个逻辑。
第三种情况有点复杂。
这种情况下，当获取到一个等待发送者，对于接收者来说，如果我们直接拿它的发送数据返回会发生什么？举个例子
上图，channel满了，且sendq有一个等待发送者(假设是G8，发送数据为800)，此时执行接收操作，也就出现上述第三种情况。
如果此时我们直接拿G8的数据，那么数据就不能保证先入先出了。
所以正确的操作是，读取当前recvx位置(0)buffer值100，然后把G8的数据800拷贝到0的位置，最后把recvq的位置向前移动，同步发送位置sendx等于recvq。这里，可以思考下为啥？
到这里缓冲channel的核心流程就说完了。如图，
另外后台回复channel有我准备的一个小ppt，可以跟着一起看。</description>
    </item>
    
    <item>
      <title>channel原理解析(二)</title>
      <link>https://www.syst.top/posts/go/channel2/</link>
      <pubDate>Sun, 10 Oct 2021 21:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/channel2/</guid>
      <description>上一篇文章主要介绍channel运行时是通过hchan表示的，也简单说明了hchan各个字段的含义。
我们提到，对channel的操作，本质上就是对hchan里字段的操作。因为在操作的过程中使用了互斥锁，所以保证了channel的并发安全。
这篇文章主要通过现实生活的一些例子来说明channel的一些原理，当然还是不会涉及过多源码。
无缓冲 我们都知道，channel分为无缓冲和缓冲。这两者最大的区别是什么？
我们用一个现实生活的快递例子来说明。
上面场景是快递员在等小库，当然反过来小库也可能在等快递员。
如果没有快递柜，快递员在送快递的过程中，如果家里没人，他就得在那等着，等着有人来签收快递，他才送货结束。
客户在快递员到来之前，他也不能离开家，不然快递来了没人收，所以他也得等到快递员上门，签字收了快递，他才算收货结束。
当然，客户不止有这家快递，如果快递员A在等的时候又来一个快递员B给他送货。这个快递员B不仅得等着，还得排队。等到客户到家后，肯定是先签收A的快递，然后再签收B的快递。
对应到无缓冲channel，
发送数据的时候，如果没有对应的接收者ready，那么发送者就进入到等待发送队列中，等待有对应的接收者唤醒它。
接收数据的时候，如果没有对应的发送者ready，那么接收者就进入到等待接收队列中，等待有对应的发送者唤醒它。
还记得上一篇文章我们介绍过hchan的结构吗。
其中recvq 表示等待接收消息的队列，sendq表示等待发送消息的队列。
我们来看waitq。
本质上waitq就是一个链表，更确切的说是一个双向循环的链表。其中waitq记录了链表的头尾，sudog记录了当前等待者的上一个等待者(prev)和下一个等待者(next)。
这就好像小库在签收完A的快递后喊，下一个是谁啊？
A会说:我的下一个是B。
B会说:是我。我记得我上一个是A，目前我没有下一个，所以我是最后一个。
缓冲 看完了无缓冲队列，我们再来看缓冲队列。还是用上面的故事，
只要快递柜有空闲柜子，快递员就可以直接把快递放到柜子里，让客户自己去柜子拿。如果发送没有空闲的柜子，那就只能等，等到别人告诉我有空闲柜子，我再把快递放到空出来的柜子里。
对应到缓冲channel，上面的快递柜，就是缓冲channel中存储数据的buffer。
对于发送者来说：只要缓冲区未满，发送者就可以继续发送数据存放在缓冲区。一旦缓冲区满了，发送者就只能进入到等待发送队列中，等待有对应的接收者唤醒它，然后它再把数据放入到刚刚被取走数据的位置。
对于接收者来说：只要缓冲区不为空，接收者就可以继续接收数据。一旦缓冲区空了，那么接收者就只能进入到等待接收队列中，等待有对应的发送者唤醒它。
上面还有什么问题吗？还真有。
我们取快递的时候，你一定会按照快递放入到快递柜的先后顺序取快递吗？咋么可能。
但是在channel中，是会保证消息的先进先出(FIFO)关系的。至于咋么保证的，我们终结篇解析代码细节的时候再说。
总结 这篇文章主要通过一个快递的例子来介绍channel操作的原理。下一篇我们介绍channel针对上述处理的细节逻辑。</description>
    </item>
    
    <item>
      <title>对CAP理论的理解</title>
      <link>https://www.syst.top/posts/go/dtm/</link>
      <pubDate>Sun, 10 Oct 2021 21:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/dtm/</guid>
      <description>介绍 最近经常看到有人发一个Go实现的分布式事务管理器，看到star增的挺猛的，索性看看代码实现，毕竟工作中部分场景也用的上。
在写源码分析之前，我们来简单了解一些概念型的东西。
CAP 分布式系统中很大的一个难点在于各个节点之间的状态如何同步，CAP就是分布式系统领域一条已经被证明的定律。
其中各个字母的含义如下，
 Consistency(一致性) Availability(可用性) Partition tolerance(分区容忍性)  下面我们用一些简单的例子来说明。
假设我们的系统是由两个服务组成的:G1和G2。
G1和G2维护了同一条记录V0。G1和G2可以相互通信，外部客户端(Client)可以调用任意一个服务。
当一个客户端对任意一个服务发起读|写请求，那么被请求的那个服务器根据客户端的请求，处理、响应结果。
比如客户端向G1发起一个读操作，客户端G1响应请求。
又比如客户端向G1发起一个写操作，把V0修改成V1。
Consistency(一致性) 这个一致性和事务中ACID中的C还是有区别的。事务中的C更多是指在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这里的完整性包括一些外键约束、键的唯一性等。
而分布式事务中的C指的是，写操作之后的读操作，必须返回该值，这就等同于所有节点访问的是同一份最新数据的副本。
下面是一个非一致性的例子。
客户端成功请求G1服务器写V1。由于网络分区，导致G1数据不能同步到G2，此时客户端从G2读取数据，依旧返回V0。
来看一个满足一致性的例子。
在这个系统中，G1收到客户端写V1的操作，G1在修改自身数据的同时，会把V1数据同步到G2。G1在收到G2的响应后，才向客户端响应结果。这样，之后无论客户端从哪个节点读取数据，都能获取到V1值。
Availability(可用性) 可用性指的是系统中非故障节点接收到的每一个请求都必须响应。
在一个可用的系统中，如果客户端向服务器发送一个请求，那么服务器必须响应客户端每一个请求，不允许忽略客户端请求。
Partition Tolerance(分区容忍性) 什么分区？
 网络分区。
 网络分区咋么理解？
 假设有两台服务器A和B，本来他们两是正常通信的，不知道啥原因，他们之间的网络链接断开，导致无法正常通信。此时本来在同一个网络的AB，发生了网络分区。变成了A所在的A网络和B所在的B网络。这就是网络分区。
 容忍性是指什么？
 当一个服务的多台服务器发生上述网络分区的时候，系统依旧能正常提供服务。
 对CAP的误解 网上很多文章都是这么说的：
 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项，这被称为CAP定律。
 似乎CAP被解释成一种三选二的定律。
看到一篇文章CAP Twelve Years Later: How the &amp;quot;Rules&amp;quot; Have Changed有一段CAP的完整表述：
 The CAP theorem asserts that any net­worked shared-data system can have only two of three desirable properties。</description>
    </item>
    
    <item>
      <title>超实用的 gRPC 客户端调试工具</title>
      <link>https://www.syst.top/posts/go/grpc/</link>
      <pubDate>Tue, 27 Jul 2021 10:01:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/grpc/</guid>
      <description>介绍 正好看到董泽润老哥写了一篇关于使用 WireShark 分析 gRPC 流量的文章，学到了。
那我就介绍两个日常开发使用过的两款 gRPC 客户端调试工具吧。
Evans Evans 有两种模式：REPL 和 CLI。比起其他 gRPC 客户端,更具有表现力。并且它还支持自动补全功能。
它的安装非常方便，在 Mac 上我们只需要执行以下两行命令即可。
$ brew tap ktr0731/evans $ brew install evans 我们来操作一下 REPL 模式。
首先我们需要有一个 pb 文件，假设你的文件在 api/api.proto，我们只需要这样： 默认地址为 127.0.0.1:50051，当然你可以通过 --host 和 --port 来指定服务器。 上图的命令:
 show package 读取 pb 包名， show service 显示对应服务列表。 call xxx 调用 grpc 服务&amp;hellip;&amp;hellip; &amp;hellip;..  更多命令可自行查阅官网。
除了上述这种直接引入 pb 文件外，我们还可以通过 gRPC 反射包(reflection)， 将 grpc.Server 注册到反射服务中, 这样的话，就可以通过 reflection 提供的反射服务查询到对应的 gRPC 服务或者调用 gRPC 服务。</description>
    </item>
    
    <item>
      <title>go并发-工作池模式</title>
      <link>https://www.syst.top/posts/go/worker-pool/</link>
      <pubDate>Thu, 01 Jul 2021 23:37:45 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/worker-pool/</guid>
      <description>开篇 之前写过一篇文章，它有个响亮的名字: Handling 1 Million Requests per Minute with Go。 这是国外的一个作者写的，我做了一篇说明。起的也是这个标题， 阅读量是我最好的一篇，果然文章都是靠标题出彩的&amp;hellip;..
今天偶然看到另一篇文章(原文在文末)。两篇文章原理相似:有一批工作任务(job)，通过工作池(worker-pool)的方式，达到多 worker 并发处理 job 的效果。
他们还是有很多不同的点，实现上差别也是蛮大的。
首先上一篇文章我放了一张图片，大概就是上篇整体的工作流。  每个 worker 处理完任务就好，不关心结果,不对结果做进一步处理。 只要请求不停止，程序就不会停止，没有控制机制，除非宕机。  这篇文章不同点在于:
首先数据会从 generate (生产数据)-&amp;gt;并发处理数据-&amp;gt;处理结果聚合。 图大概是这样的, 然后它可以通过 context.context 达到控制工作池停止工作的效果。
最后通过代码，你会发现它不是传统意义上的 worker-pool，后面会说明。
下图能清晰表达整体流程了。 顺便说一句，这篇文章实现的代码比 Handling 1 Million Requests per Minute with Go 的代码简单多了。
首先看 job。
package wpool import ( &amp;#34;context&amp;#34; ) type JobID string type jobType string type jobMetadata map[string]interface{} type ExecutionFn func(ctx context.Context, args interface{}) (interface{}, error) type JobDescriptor struct { ID JobID JType jobType Metadata map[string]interface{} } type Result struct { Value interface{} Err error Descriptor JobDescriptor } type Job struct { Descriptor JobDescriptor ExecFn ExecutionFn Args interface{} } // 处理 job 逻辑,处理结果包装成 Result 结果 func (j Job) execute(ctx context.</description>
    </item>
    
    <item>
      <title>leetcode 337 House Robber III</title>
      <link>https://www.syst.top/leetcode/337-house-robbe-riil/</link>
      <pubDate>Mon, 31 May 2021 00:36:26 +0800</pubDate>
      
      <guid>https://www.syst.top/leetcode/337-house-robbe-riil/</guid>
      <description>题目介绍 这是 House Robber III。
这道题和之前两个版本最大不同在于引入了二叉树。 树的每个节点(具体的房子)都有对应的值(金额)。每个节点有两种状态，偷或者不偷。 规则是不能同时偷父子节点， 比如上图，如果选择偷 A 节点，那么 B 和 C 就不能偷，既然 B 和 C 不能偷，那么 DEFG 就可以偷的。 因为 DEFG 和 A 是子孙关系，而不是父子关系。
这样的背景下，求小偷能偷的最大金额?
暴力递归 我们还是用上图的那个例子。我们可以直接求出最大金额,伪代码如下
/** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ // 求当前A节点能偷的最大金额res // 伪代码 item := node.Val + node.Left.Left.Val + node.Left.Right.Val + node.Right.Left.Val + node.Right.Right.Val res := max(item, node.</description>
    </item>
    
    <item>
      <title>leetcode 213 House Robber II</title>
      <link>https://www.syst.top/leetcode/213-house-robbe-rii/</link>
      <pubDate>Sun, 16 May 2021 00:17:52 +0800</pubDate>
      
      <guid>https://www.syst.top/leetcode/213-house-robbe-rii/</guid>
      <description>介绍 这是 House Robber II，也就是 I 的变型版本。II 和 I 的最大区别在于 II 把房子围城一个圈了. 你可以理解成环形链表。这样对小偷打击还是蛮大的，这意味着第一幢房子和最后一幢房子是紧挨着的。不能同时偷。 之前我们提到，相邻两家不能同时偷。如果只有一家，那么根本构不成相邻的条件，就偷唯一的那户人家。 如果有两家，那么偷的必然是两家中钱多的那家。
那如果总数大于 2 家呢？
对于第 n 家来说，只有两种选择:偷或者不偷。
是咋么计算出当前这家是否要偷的呢。
我们假设当前这家编号为 n,那么
max(我偷第 n 家的钱 + sum(截止第 n-2 家偷的钱), sum(截止第 n-1 家偷的钱，因为既然 n-1 家偷了，那么 n 必然是不能偷了))。
这才是这道题关于动态规划最核心的一个点。
看懂了吗？没看懂也没关系，手把手摸个图片出来。 还没看懂，加我微信 remember_wuqinqiang 我告诉你。这里顺便打个广告，没加我好友的赶紧加我好友。
最后，还需要考虑一个问题，如何确保偷了第一家就不偷最后一家，偷最后一家就不偷第一家。 很简单，直接定义两个dp，一个范围不包括第一家，一个范围不包括最后一家。 最后我们变成了求:
// 伪代码 最佳偷钱:=max(dp[不包括第一家],dp[不包括最后一家]) 那么剩下的就是对两个dp的状态转移公式了。
func rob(nums []int) int { n := len(nums) if n == 0 { return 0 } if n == 1 { return nums[0] } dp1, dp2 := make([]int, n), make([]int, n) dp1[0] = nums[0] dp1[1] = max(dp1[0], nums[1]) dp2[0] = 0 //dp2 不算第一家了 	dp2[1] = max(dp2[0], nums[1]) for i := 2; i &amp;lt; n; i++ { if i &amp;lt; n-1 { // dp1 不算最后一家 	dp1[i] = max(dp1[i-1], dp1[i-2]+nums[i]) } else { dp1[i] = dp1[i-1] } dp2[i] = max(dp2[i-1], dp2[i-2]+nums[i]) } return max(dp2[n-1], dp1[n-1]) } func max(x int, y int) int { if x &amp;gt; y { return x } return y } 其实代码还能更简洁。</description>
    </item>
    
    <item>
      <title>channel原理解析</title>
      <link>https://www.syst.top/posts/go/channel/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/channel/</guid>
      <description>躺的太久了，该起床了。宁可我卷死别人，不能让别人卷我。
之前断断续续看过Go几个模块的源码，可从未下笔，导致有些细节记不起来了。打算写一些文章重新记录。
channel源码解析的文章太多了。只用一篇文章的长篇大论大部分人没耐心看完，所以我打算分开写，最后附上完整的ppt。
当然这其中不会涉及过多细节源码，因为有时候，细节是魔鬼。
介绍 channel一些基础介绍这里就不过多涉及了，都1202年了，我不相信用过Go的人没用过channel。
当然下图也涵盖了大部分使用方法。注意是使用姿势，而不是模式。
顺便再提一句，有一道使用channel进行任务编排的经典的题。题目如下，
有四个goroutine，编号为 1、2、3、4。每秒钟会有一个 goroutine打印自己的编号。请你实现这个程序，让输出的编号总是按照 1、2、3、4、1、2、3、4、……的顺序打印出来。就像这样，
可以自己先思考下，代码也可以通过后台回复击鼓传花获取。
原理解析 从一个简单的例子说起。
创建一个main.go文件，代码如下，
我们来看看这段代码编译以后长啥样。
想得到go程序的汇编代码并不难。
可以使用go tool compile -N -l -S main.go生成汇编代码：
或者使用go tool compile -N -l main.go 先编译出代码，然后再使用go tool objdump main.o反汇编出代码。
当然，通过go build -gcflags -S main.go同样可以得到汇编的代码。
上面两种我就不演示了，可以自行实验。他们之中flag的具体含义也可以自行了解。
如果你觉得上面要自己敲代码比较麻烦，我推荐一个更加直接可视化的工具。
综上，从编译的代码我们可以看出，上述初始化一个channel,
ch := make(chan struct{}) 实际上调用的是runtime.makechan。我们来了解一下runtime.makechan。
从函数中，我们能知道最终返回一个runtime.hchan的指针。
runtime.hchan结构。
我们先来解释hchan结构体各个字段的含义，之后在案例介绍中会更加详细的说明他们的作用。
我们先来看qcount和dataqsiz有什么区别？
你去银行办事，银行有5个办事窗口，那么dataqsiz就等于5。在这里体现的是channel的容量为5。去银行的时候，当前有3个窗口有人正在办事，那么qcount就等于3，体现channel当前有3个数据元素。那么此时银行还可以再接待2个客户，对应还可以往channel发送2个数据元素。
其他字段现在看看说明就行了，后面会细讲。
到这里我们就知道创建一个channel本质上就是得到一个runtime.hchan的指针，后续对此chan的操作，无非就是对结构体字段进行相对应的操作。
同时我们也能猜出，为啥channel能在不同的g中传递消息，而对于使用者来说不用担心并发的问题，其实就是hchan内部使用互斥锁来保证了并发安全。
最后我们来看一下runtime.makechan函数核心实现，当然注释已经很明白了。
可以看到创建的时候有一段switch分支代码，那么什么情况下会走对应的case呢?
根据上面的信息，我们可以得出，
 如果创建一个无缓冲channel ，那么只需要为runtime.hchan本身分配一段内存空间即可。 如果创建的缓冲channel 存储的类型不是指针类型，会为当前 channel 和存储类型元素的缓冲区，分配一块连续的内存空间。 在默认情况下(缓冲channel存储类型包含指针)，会单独为runtime.hchan和缓冲区分配内存。  总结 这篇我们主要介绍了如何获取go程序的汇编代码，通过汇编代码知道创建channel的具体函数runtime.makechan，同时我们还知道不同的创建姿势会导致走向不同的内存空间分配。最后通过创建函数我们知道channel在程序运行时使用runtime.hchan来表示。</description>
    </item>
    
    <item>
      <title>iota 在 Go 中的使用 </title>
      <link>https://www.syst.top/posts/go/enum/</link>
      <pubDate>Sun, 25 Apr 2021 22:25:52 +0800</pubDate>
      
      <guid>https://www.syst.top/posts/go/enum/</guid>
      <description>介绍 Go 语言实际上没有直接支持枚举的关键字。一般我们都是通过 const + iota 实现枚举的能力。
有人要问了，为什么一定要使用枚举呢？stackoverflow 上有一个高赞的回答，如下:
You should always use enums when a variable (especially a method parameter) can only take one out of a small set of possible values. Examples would be things like type constants (contract status: &amp;quot;permanent&amp;quot;, &amp;quot;temp&amp;quot;, &amp;quot;apprentice&amp;quot;), or flags (&amp;quot;execute now&amp;quot;, &amp;quot;defer execution&amp;quot;). If you use enums instead of integers (or String codes), you increase compile-time checking and avoid errors from passing in invalid constants, and you document which values are legal to use.</description>
    </item>
    
  </channel>
</rss>
