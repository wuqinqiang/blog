<!DOCTYPE html>
<html lang="zh-hans">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="Gnet原理解析">
<meta itemprop="description" content="距离上次写文章过了一月有余，这段时间着实太躺了。以至于昨晚做了一个噩梦，醒来的时候狠狠的抽了自己两巴掌，不能这么躺了。
上面当然是个笑话。
开篇 上一篇我们分析了Go原生网络模型以及部分源码，绝大部分场景下(99%)，使用原生netpoll已经足够了。
但是在一些海量并发连接下，原生netpoll会为每一个连接都开启一个goroutine处理，也就是1千万的连接就会创建一千万个goroutine。这就给了这些特殊场景下的优化空间，这也是像gnet和cloudwego/netpoll诞生的原因之一吧。
本质上他们的底层核心都是一样的，都是基于epoll(linux)实现的。
只是对事件发生后，每个库的处理方式会有所不同。
本篇文章主要分析gnet的。至于使用姿势就不发了，gnet有对应的demo库，可以自行体验。
架构 直接引用gnet官网的一张图
gnet采用的是『主从多 Reactors』。也就是一个主线程负责监听端口连接，当一个客户端连接到来时，就把这个连接根据负载均衡算法分配给其中一个sub线程，由对应的sub线程去处理这个连接的读写事件以及管理它的死亡。
下面这张图就更清晰了。
核心结构 我们先解释gnet的一些核心结构。
engine就是程序最上层的结构了。
  ln对应的listener就是服务启动后对应监听端口的监听器。
  lb对应的loadBalancer就是负载均衡器。也就是当客户端连接服务时，负载均衡器会选择一个sub线程，把连接交给此线程处理。
  mainLoop 就是我们的主线程了，对应的结构eventloop。当然我们的sub线程结构也是eventloop。结构相同，不同的是职责。主线程负责的是监听端口发生的客户端连接事件，然后再由负载均衡器把连接分配给一个sub线程。而sub线程负责的是绑定分配给他的连接(不止一个)，且等待自己管理的所有连接后续读写事件，并进行处理。
  接着看eventloop。
 netpoll.Poller:每一个 eventloop都对应一个epoll或者kqueue。 buffer用来作为读消息的缓冲区。 connCoun记录当前eventloop存储的tcp连接数。 udpSockets和connetcions分别管理着这个eventloop下所有的udp socket和tcp连接，注意他们的结构map。这里的int类型存储的就是fd。  对应conn结构，
这里面有几个字段介绍下，
 buffer:存储当前conn对端(client)发送的最新数据，比如发送了三次，那个此时buffer存储的是第三次的数据,代码里有。 inboundBuffer:存储对端发送的且未被用户读取的剩余数据，还是个Ring Buffer。 outboundBuffer:存储还未发送给对端的数据。(比如服务端响应客户端的数据，由于conn fd是不阻塞的，调用write返回不可写的时候，就可以先把数据放到这里)  conn相当于每个连接都会有自己独立的缓存空间。这样做是为了减少集中式管理内存带来的锁问题。使用Ring buffer是为了增加空间的复用性。
整体结构就这些。
核心逻辑 当程序启动时，
会根据用户设置的options明确eventloop循环的数量，也就是有多少个sub线程。再进一步说，在linux环境就是会创建多少个epoll对象。
那么整个程序的epoll对象就是count(sub)&#43;1(main Listener)。
上图就是我说的，会根据设置的数量创建对应的eventloop,把对应的eventloop 注册到负载均衡器中。
当新连接到来时，就可以根据一定的算法(gnet提供了轮询、最少连接以及hash)挑选其中一个eventloop把连接分配给它。
我们先来看主线程，(由于我使用的是mac,所以后面关于IO多路复用，实现部分就是kqueue代码了，当然原理是一样的)
Polling就是等待网络事件到来，传递了一个闭包参数，更确切的说是一个事件到来时的回调函数，从名字可以看出，就是处理新连接的。
至于Polling函数，
逻辑很简单，一个for循环等待事件到来，然后处理事件。
主线程的事件分两种，
一种是正常的fd发生网络连接事件，
一种是通过NOTE_TRIGGER立即激活的事件。
通过NOTE_TRIGGER触发告诉你队列里有task任务，去执行task任务。
如果是正常的网络事件到来，就处理闭包函数，主线程处理的就是上面的accept连接函数。
accept连接逻辑很简单，拿到连接的fd。设置fd非阻塞模式(想想连接是阻塞的会咋么样?),然后根据负载均衡算法选择一个sub 线程，通过register函数把此连接分配给它。
register做了两件事，首先需要把当前连接注册到当前sub 线程的epoll or kqueue 对象中,新增read的flag。"><meta itemprop="datePublished" content="2022-06-07T16:23:51+08:00" />
<meta itemprop="dateModified" content="2022-06-07T16:23:51+08:00" />
<meta itemprop="wordCount" content="76">
<meta itemprop="keywords" content="go,net," /><meta property="og:title" content="Gnet原理解析" />
<meta property="og:description" content="距离上次写文章过了一月有余，这段时间着实太躺了。以至于昨晚做了一个噩梦，醒来的时候狠狠的抽了自己两巴掌，不能这么躺了。
上面当然是个笑话。
开篇 上一篇我们分析了Go原生网络模型以及部分源码，绝大部分场景下(99%)，使用原生netpoll已经足够了。
但是在一些海量并发连接下，原生netpoll会为每一个连接都开启一个goroutine处理，也就是1千万的连接就会创建一千万个goroutine。这就给了这些特殊场景下的优化空间，这也是像gnet和cloudwego/netpoll诞生的原因之一吧。
本质上他们的底层核心都是一样的，都是基于epoll(linux)实现的。
只是对事件发生后，每个库的处理方式会有所不同。
本篇文章主要分析gnet的。至于使用姿势就不发了，gnet有对应的demo库，可以自行体验。
架构 直接引用gnet官网的一张图
gnet采用的是『主从多 Reactors』。也就是一个主线程负责监听端口连接，当一个客户端连接到来时，就把这个连接根据负载均衡算法分配给其中一个sub线程，由对应的sub线程去处理这个连接的读写事件以及管理它的死亡。
下面这张图就更清晰了。
核心结构 我们先解释gnet的一些核心结构。
engine就是程序最上层的结构了。
  ln对应的listener就是服务启动后对应监听端口的监听器。
  lb对应的loadBalancer就是负载均衡器。也就是当客户端连接服务时，负载均衡器会选择一个sub线程，把连接交给此线程处理。
  mainLoop 就是我们的主线程了，对应的结构eventloop。当然我们的sub线程结构也是eventloop。结构相同，不同的是职责。主线程负责的是监听端口发生的客户端连接事件，然后再由负载均衡器把连接分配给一个sub线程。而sub线程负责的是绑定分配给他的连接(不止一个)，且等待自己管理的所有连接后续读写事件，并进行处理。
  接着看eventloop。
 netpoll.Poller:每一个 eventloop都对应一个epoll或者kqueue。 buffer用来作为读消息的缓冲区。 connCoun记录当前eventloop存储的tcp连接数。 udpSockets和connetcions分别管理着这个eventloop下所有的udp socket和tcp连接，注意他们的结构map。这里的int类型存储的就是fd。  对应conn结构，
这里面有几个字段介绍下，
 buffer:存储当前conn对端(client)发送的最新数据，比如发送了三次，那个此时buffer存储的是第三次的数据,代码里有。 inboundBuffer:存储对端发送的且未被用户读取的剩余数据，还是个Ring Buffer。 outboundBuffer:存储还未发送给对端的数据。(比如服务端响应客户端的数据，由于conn fd是不阻塞的，调用write返回不可写的时候，就可以先把数据放到这里)  conn相当于每个连接都会有自己独立的缓存空间。这样做是为了减少集中式管理内存带来的锁问题。使用Ring buffer是为了增加空间的复用性。
整体结构就这些。
核心逻辑 当程序启动时，
会根据用户设置的options明确eventloop循环的数量，也就是有多少个sub线程。再进一步说，在linux环境就是会创建多少个epoll对象。
那么整个程序的epoll对象就是count(sub)&#43;1(main Listener)。
上图就是我说的，会根据设置的数量创建对应的eventloop,把对应的eventloop 注册到负载均衡器中。
当新连接到来时，就可以根据一定的算法(gnet提供了轮询、最少连接以及hash)挑选其中一个eventloop把连接分配给它。
我们先来看主线程，(由于我使用的是mac,所以后面关于IO多路复用，实现部分就是kqueue代码了，当然原理是一样的)
Polling就是等待网络事件到来，传递了一个闭包参数，更确切的说是一个事件到来时的回调函数，从名字可以看出，就是处理新连接的。
至于Polling函数，
逻辑很简单，一个for循环等待事件到来，然后处理事件。
主线程的事件分两种，
一种是正常的fd发生网络连接事件，
一种是通过NOTE_TRIGGER立即激活的事件。
通过NOTE_TRIGGER触发告诉你队列里有task任务，去执行task任务。
如果是正常的网络事件到来，就处理闭包函数，主线程处理的就是上面的accept连接函数。
accept连接逻辑很简单，拿到连接的fd。设置fd非阻塞模式(想想连接是阻塞的会咋么样?),然后根据负载均衡算法选择一个sub 线程，通过register函数把此连接分配给它。
register做了两件事，首先需要把当前连接注册到当前sub 线程的epoll or kqueue 对象中,新增read的flag。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.syst.top/posts/go/gnet/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-07T16:23:51+08:00" />
<meta property="article:modified_time" content="2022-06-07T16:23:51+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Gnet原理解析"/>
<meta name="twitter:description" content="距离上次写文章过了一月有余，这段时间着实太躺了。以至于昨晚做了一个噩梦，醒来的时候狠狠的抽了自己两巴掌，不能这么躺了。
上面当然是个笑话。
开篇 上一篇我们分析了Go原生网络模型以及部分源码，绝大部分场景下(99%)，使用原生netpoll已经足够了。
但是在一些海量并发连接下，原生netpoll会为每一个连接都开启一个goroutine处理，也就是1千万的连接就会创建一千万个goroutine。这就给了这些特殊场景下的优化空间，这也是像gnet和cloudwego/netpoll诞生的原因之一吧。
本质上他们的底层核心都是一样的，都是基于epoll(linux)实现的。
只是对事件发生后，每个库的处理方式会有所不同。
本篇文章主要分析gnet的。至于使用姿势就不发了，gnet有对应的demo库，可以自行体验。
架构 直接引用gnet官网的一张图
gnet采用的是『主从多 Reactors』。也就是一个主线程负责监听端口连接，当一个客户端连接到来时，就把这个连接根据负载均衡算法分配给其中一个sub线程，由对应的sub线程去处理这个连接的读写事件以及管理它的死亡。
下面这张图就更清晰了。
核心结构 我们先解释gnet的一些核心结构。
engine就是程序最上层的结构了。
  ln对应的listener就是服务启动后对应监听端口的监听器。
  lb对应的loadBalancer就是负载均衡器。也就是当客户端连接服务时，负载均衡器会选择一个sub线程，把连接交给此线程处理。
  mainLoop 就是我们的主线程了，对应的结构eventloop。当然我们的sub线程结构也是eventloop。结构相同，不同的是职责。主线程负责的是监听端口发生的客户端连接事件，然后再由负载均衡器把连接分配给一个sub线程。而sub线程负责的是绑定分配给他的连接(不止一个)，且等待自己管理的所有连接后续读写事件，并进行处理。
  接着看eventloop。
 netpoll.Poller:每一个 eventloop都对应一个epoll或者kqueue。 buffer用来作为读消息的缓冲区。 connCoun记录当前eventloop存储的tcp连接数。 udpSockets和connetcions分别管理着这个eventloop下所有的udp socket和tcp连接，注意他们的结构map。这里的int类型存储的就是fd。  对应conn结构，
这里面有几个字段介绍下，
 buffer:存储当前conn对端(client)发送的最新数据，比如发送了三次，那个此时buffer存储的是第三次的数据,代码里有。 inboundBuffer:存储对端发送的且未被用户读取的剩余数据，还是个Ring Buffer。 outboundBuffer:存储还未发送给对端的数据。(比如服务端响应客户端的数据，由于conn fd是不阻塞的，调用write返回不可写的时候，就可以先把数据放到这里)  conn相当于每个连接都会有自己独立的缓存空间。这样做是为了减少集中式管理内存带来的锁问题。使用Ring buffer是为了增加空间的复用性。
整体结构就这些。
核心逻辑 当程序启动时，
会根据用户设置的options明确eventloop循环的数量，也就是有多少个sub线程。再进一步说，在linux环境就是会创建多少个epoll对象。
那么整个程序的epoll对象就是count(sub)&#43;1(main Listener)。
上图就是我说的，会根据设置的数量创建对应的eventloop,把对应的eventloop 注册到负载均衡器中。
当新连接到来时，就可以根据一定的算法(gnet提供了轮询、最少连接以及hash)挑选其中一个eventloop把连接分配给它。
我们先来看主线程，(由于我使用的是mac,所以后面关于IO多路复用，实现部分就是kqueue代码了，当然原理是一样的)
Polling就是等待网络事件到来，传递了一个闭包参数，更确切的说是一个事件到来时的回调函数，从名字可以看出，就是处理新连接的。
至于Polling函数，
逻辑很简单，一个for循环等待事件到来，然后处理事件。
主线程的事件分两种，
一种是正常的fd发生网络连接事件，
一种是通过NOTE_TRIGGER立即激活的事件。
通过NOTE_TRIGGER触发告诉你队列里有task任务，去执行task任务。
如果是正常的网络事件到来，就处理闭包函数，主线程处理的就是上面的accept连接函数。
accept连接逻辑很简单，拿到连接的fd。设置fd非阻塞模式(想想连接是阻塞的会咋么样?),然后根据负载均衡算法选择一个sub 线程，通过register函数把此连接分配给它。
register做了两件事，首先需要把当前连接注册到当前sub 线程的epoll or kqueue 对象中,新增read的flag。"/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>Gnet原理解析</title>
	<link rel="stylesheet" href="https://www.syst.top/css/style.min.cb0663fd19952012fdb4a1345792a808ae19eb828578bde6eeae217ff1fb1e8b.css">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://www.syst.top">是不是很酷</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					<a href="https://www.syst.top/posts/">文章</a>
					<a href="https://www.syst.top/leetcode/">刷题</a>
					<a href="https://www.syst.top/lives/">生活</a>
					<a href="https://www.syst.top/readings/">读书笔记</a>
					<a href="https://www.syst.top/friends/">朋友</a>
					<a href="https://go.aabbccm.com">grpc-shop</a>
				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<button id="toc-btn" class="hdr-btn desktop-only-ib" title="Table of Contents"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-list"><line x1="8" y1="6" x2="21" y2="6"></line><line x1="8" y1="12" x2="21" y2="12"></line><line x1="8" y1="18" x2="21" y2="18"></line><line x1="3" y1="6" x2="3" y2="6"></line><line x1="3" y1="12" x2="3" y2="12"></line><line x1="3" y1="18" x2="3" y2="18"></line></svg></button><span class="hdr-social hide-in-mobile"><a href="https://github.com/wuqinqiang" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://www.syst.top/posts/">文章</a></li>
			<li><a href="https://www.syst.top/tags/">标签</a></li>
			<li><a href="https://www.syst.top/about/">关于</a></li>
		</ul>
	</div>


	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Jun 7, 2022</span></div>
				<h1>Gnet原理解析</h1>
			</header>
			<div class="content">
				<p>距离上次写文章过了一月有余，这段时间着实太躺了。以至于昨晚做了一个噩梦，醒来的时候狠狠的抽了自己两巴掌，不能这么躺了。</p>
<p>上面当然是个笑话。</p>
<h3 id="开篇">开篇<a href="#开篇" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>上一篇我们分析了Go原生网络模型以及部分源码，绝大部分场景下(99%)，使用原生netpoll已经足够了。</p>
<p>但是在一些海量并发连接下，原生netpoll会为每一个连接都开启一个goroutine处理，也就是1千万的连接就会创建一千万个goroutine。这就给了这些特殊场景下的优化空间，这也是像gnet和cloudwego/netpoll诞生的原因之一吧。</p>
<p>本质上他们的底层核心都是一样的，都是基于epoll(linux)实现的。</p>
<p>只是对事件发生后，每个库的处理方式会有所不同。</p>
<p>本篇文章主要分析gnet的。至于使用姿势就不发了，gnet有对应的demo库，可以自行体验。</p>
<h3 id="架构">架构<a href="#架构" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>直接引用gnet官网的一张图</p>
<p><img src="https://cdn.syst.top/net1.png" alt="截屏2022-06-02 15.03.18"></p>
<p>gnet采用的是『主从多 Reactors』。也就是一个主线程负责监听端口连接，当一个客户端连接到来时，就把这个连接根据负载均衡算法分配给其中一个sub线程，由对应的sub线程去处理这个连接的读写事件以及管理它的死亡。</p>
<p>下面这张图就更清晰了。</p>
<p><img src="https://cdn.syst.top/net2.png" alt="图片来源gnet官网"></p>
<h3 id="核心结构">核心结构<a href="#核心结构" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>我们先解释gnet的一些核心结构。</p>
<p><img src="https://cdn.syst.top/net4.png" alt="image-20220602153051260"></p>
<p>engine就是程序最上层的结构了。</p>
<ul>
<li>
<p>ln对应的listener就是服务启动后对应监听端口的监听器。</p>
</li>
<li>
<p>lb对应的loadBalancer就是负载均衡器。也就是当客户端连接服务时，负载均衡器会选择一个sub线程，把连接交给此线程处理。</p>
</li>
<li>
<p>mainLoop 就是我们的主线程了，对应的结构eventloop。当然我们的sub线程结构也是eventloop。结构相同，不同的是职责。主线程负责的是监听端口发生的客户端连接事件，然后再由负载均衡器把连接分配给一个sub线程。而sub线程负责的是绑定分配给他的连接(不止一个)，且等待自己管理的所有连接后续读写事件，并进行处理。</p>
</li>
</ul>
<p>接着看eventloop。</p>
<p><img src="https://cdn.syst.top/net5.png" alt="image-20220602154501439"></p>
<ul>
<li>netpoll.Poller:每一个 eventloop都对应一个epoll或者kqueue。</li>
<li>buffer用来作为读消息的缓冲区。</li>
<li>connCoun记录当前eventloop存储的tcp连接数。</li>
<li>udpSockets和connetcions分别管理着这个eventloop下所有的udp socket和tcp连接，注意他们的结构map。这里的int类型存储的就是fd。</li>
</ul>
<p>对应conn结构，</p>
<p><img src="https://cdn.syst.top/net5-1.png" alt="image-20220608175339906"></p>
<p>这里面有几个字段介绍下，</p>
<ul>
<li>buffer:存储当前conn对端(client)发送的最新数据，比如发送了三次，那个此时buffer存储的是第三次的数据,代码里有。</li>
<li>inboundBuffer:存储对端发送的且未被用户读取的剩余数据，还是个Ring Buffer。</li>
<li>outboundBuffer:存储还未发送给对端的数据。(比如服务端响应客户端的数据，由于conn fd是不阻塞的，调用write返回不可写的时候，就可以先把数据放到这里)</li>
</ul>
<p>conn相当于每个连接都会有自己独立的缓存空间。这样做是为了减少集中式管理内存带来的锁问题。使用Ring buffer是为了增加空间的复用性。</p>
<p>整体结构就这些。</p>
<h3 id="核心逻辑">核心逻辑<a href="#核心逻辑" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>当程序启动时，</p>
<p><img src="https://cdn.syst.top/net3.png" alt="net3"></p>
<p>会根据用户设置的options明确eventloop循环的数量，也就是有多少个sub线程。再进一步说，在linux环境就是会创建多少个epoll对象。</p>
<p>那么整个程序的epoll对象就是count(sub)+1(main Listener)。</p>
<p><img src="https://cdn.syst.top/net6.png" alt="image-20220608164415565"></p>
<p>上图就是我说的，会根据设置的数量创建对应的eventloop,把对应的eventloop 注册到负载均衡器中。</p>
<p>当新连接到来时，就可以根据一定的算法(gnet提供了轮询、最少连接以及hash)挑选其中一个eventloop把连接分配给它。</p>
<p>我们先来看主线程，(由于我使用的是mac,所以后面关于IO多路复用，实现部分就是kqueue代码了，当然原理是一样的)</p>
<p><img src="https://cdn.syst.top/net7.png" alt="image-20220608165350443"></p>
<p>Polling就是等待网络事件到来，传递了一个闭包参数，更确切的说是一个事件到来时的回调函数，从名字可以看出，就是处理新连接的。</p>
<p>至于Polling函数，</p>
<p><img src="https://cdn.syst.top/net8.png" alt="image-20220608170912204"></p>
<p>逻辑很简单，一个for循环等待事件到来，然后处理事件。</p>
<p>主线程的事件分两种，</p>
<p>一种是正常的fd发生网络连接事件，</p>
<p>一种是通过NOTE_TRIGGER立即激活的事件。</p>
<p><img src="https://cdn.syst.top/net9.png" alt="image-20220608171537730"></p>
<p>通过NOTE_TRIGGER触发告诉你队列里有task任务，去执行task任务。</p>
<p>如果是正常的网络事件到来，就处理闭包函数，主线程处理的就是上面的accept连接函数。</p>
<p><img src="https://cdn.syst.top/net10.png" alt="image-20220608172333749"></p>
<p>accept连接逻辑很简单，拿到连接的fd。设置fd非阻塞模式(想想连接是阻塞的会咋么样?),然后根据负载均衡算法选择一个sub 线程，通过register函数把此连接分配给它。</p>
<p><img src="https://cdn.syst.top/net11.png" alt="image-20220608173157607"></p>
<p>register做了两件事，首先需要把当前连接注册到当前sub 线程的epoll or kqueue 对象中,新增read的flag。</p>
<p>接着就是把当前连接放入到connections的map结构中 fd-&gt;conn。</p>
<p>这样当对应的sub线程事件到来时，可以通过事件的fd找到是哪个连接，进行相应的处理。</p>
<p><img src="https://cdn.syst.top/net12.png" alt="image-20220608174647390"></p>
<p>如果是可读事件，</p>
<p><img src="https://cdn.syst.top/net13.png" alt="image-20220608182813931"></p>
<p>到这里分析差不多就结束了。</p>
<h3 id="总结">总结<a href="#总结" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>在gnet里面，你可以看到，基本上所有的操作都无锁的。</p>
<p>那是因为事件到来时，采取的都是非阻塞的操作，且是串行处理对应的每个fd(conn)。每个conn操作的都是自身持有的缓存空间。同时处理完一轮触发的所有事件才会循环进入下一次等待，在此层面上解决了并发问题。</p>
<p>当然这样用户在使用的时候也需要注意一些问题，比如用户在自定义EventHandler中，如果要异步处理逻辑，就不能像下面这样开一个g然后在里面获取本次数据，</p>
<p><img src="https://cdn.syst.top/net14.png" alt="image-20220608184718192"></p>
<p>而应该先拿到数据，再异步处理。</p>
<p><img src="https://cdn.syst.top/net15.png" alt="image-20220608184937855"></p>
<p>issues上有提到，连接是使用map[int]*conn存储的。gnet本身的场景就是海量并发连接，内存会很大。进而big map存指针会对 GC造成很大的负担，毕竟它不像数组一样，是连续内存空间，易于GC扫描。</p>
<p>还有一点，在处理buffer数据的时候，就像上面看到的，本质上是将buffer数据copy给用户一份，那么就存在大量copy开销,在这一点上，字节的netpoll实现了Nocopy Buffer，改天研究一下。</p>

			</div>
			<div class="content"><br><img src="https://image.syst.top/image/wechat-qr.png"></div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://www.syst.top/tags/go">go</a></span><span class="tag"><a href="https://www.syst.top/tags/net">net</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>76 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2022-06-07 16:23 &#43;0800</p>
			</footer>
		</article>
		<aside id="toc" class="show-toc">
			<div class="toc-title">Table of Contents</div>
			<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#开篇">开篇</a></li>
        <li><a href="#架构">架构</a></li>
        <li><a href="#核心结构">核心结构</a></li>
        <li><a href="#核心逻辑">核心逻辑</a></li>
        <li><a href="#总结">总结</a></li>
      </ul>
    </li>
  </ul>
</nav>
		</aside>
		<div class="post-nav thin">
			<a class="prev-post" href="https://www.syst.top/posts/go/netpoll/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>Go netpoll大解析</span>
			</a>
		</div>
		<div id="comments" class="thin">
			<script src="https://utteranc.es/client.js"
        repo="wuqinqiang/blog"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
		</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2018 - 2022 <a href="https://www.syst.top">Remember</a> &#183; <a href="http://beian.miit.gov.cn/">浙ICP备18028603号-2</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://www.syst.top/post/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>


	<script src="https://www.syst.top/js/main.min.c8a831e54547e9c081939713d77308bf58ae5fed99a75acbcaaa14c5ce45bf89.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-166045776-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</body>

</html>
